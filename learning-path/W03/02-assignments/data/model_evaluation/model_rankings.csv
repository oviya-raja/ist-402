rank,model,lib_score,llm_score,average_score,bertscore,squad_f1,size,avg_time
1,BERT-Tiny-SQuAD,0.5605804692721799,0.7921462982056258,0.6763633837389028,0.7619922757148743,0.1702127659574468,tiny,0.007970857620239257
2,BERT-Large-SQuAD,0.6191548385627631,0.7171000813133979,0.6681274599380804,0.7900854349136353,0.28,large,0.2905200242996216
3,DistilBERT-SQuAD,0.631054521670296,0.6881278909687487,0.6595912063195224,0.7900854349136353,0.28,small,0.0492114782333374
4,RoBERTa-SQuAD2,0.6151547262186091,0.7016359092335227,0.658395317726066,0.7900854349136353,0.28,base,0.07127594947814941
5,T5-QA-Generative,0.5887415834328892,0.602186598764773,0.5954640910988311,0.8196241855621338,0.5423728813559322,base,1.080946397781372
6,DynamicRAG-8B,0.3395941674883943,0.6103992232462391,0.4749966953673167,0.686343252658844,0.0,8B,1.9367147922515868
