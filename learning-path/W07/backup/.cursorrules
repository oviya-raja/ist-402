# Assignment Management System - Cursor Rules Template
# This template works for ANY assignment - only assignment files change

## ğŸ¯ PROJECT CONTEXT

**Assignment Files (CHANGE THESE FOR EACH ASSIGNMENT):**
- `Assignment_Analysis_Prompt.md` - Contains assignment requirements, rubrics, deliverables
- `Assignment_TODO_Tracker.md` - Contains all tasks, phases, and progress tracking

**IMPORTANT:** When starting a new assignment, only update the two files above. All other files remain the same.

---

## ğŸ“‹ CORE WORKING METHODOLOGY

### 1. Initialization Protocol
When starting work on an assignment:
1. **Read Assignment Files:**
   - Read `Assignment_Analysis_Prompt.md` to understand requirements
   - Read `Assignment_TODO_Tracker.md` to see current progress
   - Read `state_tracker.json` to see current state (if exists)

2. **Load Learnings:**
   - Read `../_global_learnings/` for cross-assignment learnings
   - Read `ai-driven/learnings/` for assignment-specific learnings
   - Apply relevant learnings to current work

3. **Check State:**
   - If `ai-driven/state_tracker.json` exists, resume from last position
   - If not, start from Phase 1, Task 1

### 2. Task Execution Protocol

**Before Starting Each Task:**
1. Read current task from `Assignment_TODO_Tracker.md`
2. Check `ai-driven/state_tracker.json` for current position
3. Review relevant learnings from `ai-driven/learnings/` and `../_global_learnings/`
4. Check rubric alignment from `Assignment_Analysis_Prompt.md`

**During Task Execution:**
1. Complete the task according to requirements
2. Run self-assessment using `ai-driven/verification_checklists.md`
3. Generate task evaluation form
4. Log activity to episodic memory

**After Task Completion:**
1. **Self-Evaluation:**
   - Run `ai-driven/verification_checklists.md` task verification
   - Generate self-assessment score
   - Identify any gaps or improvements needed
   - Log to `ai-driven/self_feedback/self_assessments.md`

2. **Request Human Approval:**
   - Generate task approval form in `ai-driven/evaluations/task_evaluations.md`
   - Present work for review
   - **WAIT FOR HUMAN APPROVAL** before proceeding

3. **If Approved:**
   - Update `Assignment_TODO_Tracker.md` (mark checkbox)
   - Update `ai-driven/state_tracker.json` (increment progress)
   - Log to `ai-driven/episodic_memory/task_history.md`
   - Log to `ai-driven/episodic_memory/event_log.md`
   - Capture any learnings to `ai-driven/learnings/`
   - Proceed to next task

4. **If Rejected:**
   - Capture feedback to `ai-driven/learnings/feedback_learnings.md`
   - Update `ai-driven/self_feedback/improvement_suggestions.md`
   - Apply feedback and improve work
   - Resubmit for approval
   - Learn from mistake (update error patterns)

### 3. Phase Completion Protocol

**When All Tasks in Phase Complete:**
1. **Phase Self-Evaluation:**
   - Run phase verification checklist from `ai-driven/verification_checklists.md`
   - Assess phase objectives completion
   - Generate phase quality score
   - Log to `ai-driven/self_feedback/self_assessments.md`

2. **Generate Phase Evaluation:**
   - Create comprehensive phase evaluation in `ai-driven/evaluations/phase_evaluations.md`
   - Include: objectives met, quality score, rubric alignment, issues, improvements
   - **WAIT FOR HUMAN APPROVAL** before unlocking next phase

3. **If Approved:**
   - Update phase status in `Assignment_TODO_Tracker.md`
   - Update `ai-driven/state_tracker.json`
   - Log phase completion to `ai-driven/episodic_memory/`
   - Extract learnings and save to `ai-driven/learnings/`
   - Unlock next phase

4. **If Rejected:**
   - Capture detailed feedback
   - Create improvement plan
   - Update learning database
   - Address issues before proceeding

### 4. Progress Tracking Protocol

**Always Update These Files:**
- `ai-driven/state_tracker.json` - Real-time state (updated after every action)
- `Assignment_TODO_Tracker.md` - Task checkboxes and completion counts
- `ai-driven/episodic_memory/event_log.md` - Chronological event log
- `ai-driven/episodic_memory/task_history.md` - Task completion log

**IMPORTANT:** Only update existing files. Do NOT create new files outside `ai-driven/` unless explicitly requested.

**Progress Calculation:**
- Read `Assignment_TODO_Tracker.md` to count completed tasks
- Calculate percentages: (completed/total) Ã— 100
- Update progress tables in tracker
- Update `ai-driven/state_tracker.json` progress metrics

---

## ğŸ” VERIFICATION & QUALITY GATES

### Task Verification Checklist
Before marking any task complete, verify:
- [ ] Task actually meets requirements from Assignment_Analysis_Prompt.md
- [ ] Quality meets minimum standards (check ai-driven/learnings/quality_improvements.md)
- [ ] Rubric alignment checked (from Assignment_Analysis_Prompt.md)
- [ ] Documentation is complete
- [ ] Self-assessment completed
- [ ] Human approval obtained

### Phase Verification Checklist
Before marking phase complete, verify:
- [ ] All tasks in phase are completed and approved
- [ ] Phase objectives met (from Assignment_TODO_Tracker.md)
- [ ] Quality standards met
- [ ] Rubric alignment verified
- [ ] Phase evaluation completed
- [ ] Human approval obtained

---

## ğŸ§  LEARNING SYSTEM

### Learning Capture Protocol

**After Each Human Feedback:**
1. **Immediate Learning:**
   - Store feedback in `ai-driven/learnings/feedback_learnings.md`
   - Identify pattern (error type, quality issue, etc.)
   - Update relevant learning file

2. **Pattern Recognition:**
   - Check if similar feedback received before
   - If yes, update pattern frequency
   - If no, create new pattern entry

3. **Apply to Future Work:**
   - Update verification checklists if needed
   - Update quality standards
   - Add to error patterns to avoid
   - Add to success patterns to replicate

### Cross-Assignment Learning

**At Assignment Completion:**
1. **Extract Key Learnings:**
   - Review all learnings from this assignment
   - Identify universally applicable patterns
   - Extract best practices

2. **Update Global Learnings:**
   - Save to `../_global_learnings/` directory
   - Categorize by type (quality, process, common errors, etc.)
   - Make available for future assignments

3. **Template Improvements:**
   - If process improvements identified, update this .cursorrules
   - Update `ai-driven/verification_checklists.md`
   - Improve evaluation forms in `ai-driven/evaluations/`

### Learning Application Protocol

**When Starting New Assignment:**
1. Load global learnings from `../_global_learnings/`
2. Check for similar assignment types
3. Apply relevant patterns and standards
4. Avoid known error patterns
5. Replicate success patterns

---

## ğŸ“ STATE TRACKING & "WHERE ARE YOU" SYSTEM

### State Tracker Structure
The `ai-driven/state_tracker.json` file contains:
- Current phase and task
- Progress percentages
- Recent activity log
- Current blockers
- Next steps
- Evaluation status
- Recent learnings applied

### "Where Are You" Query Response

**When user asks "where are you", "status", "current state", or similar:**
1. Read `ai-driven/state_tracker.json`
2. Read last 5 entries from `ai-driven/episodic_memory/event_log.md`
3. Read recent learnings from `ai-driven/learnings/`
4. Check evaluation status
5. Generate comprehensive status report with:
   - Current phase and task
   - Progress percentages
   - Recent activity
   - Blockers/issues
   - Next steps
   - Recent learnings
   - Evaluation status

**Format the response clearly with:**
- Current position (phase, task, description)
- Progress metrics (overall, phase, deliverable)
- Recent activity timeline
- Current blockers
- Next steps
- Recent learnings applied
- Evaluation/approval status

---

## ğŸ“ EPISODIC MEMORY SYSTEM

### Event Logging Protocol

**Log Every Significant Event:**
- Task starts/completions
- Phase transitions
- Human approvals/rejections
- Learnings captured
- Decisions made
- Blockers encountered/resolved

**Event Log Format:**
```markdown
**Timestamp:** YYYY-MM-DDTHH:MM:SSZ
**Event Type:** [Task Completion | Phase Transition | Approval | Learning | Decision]
**Context:** Brief description
**Outcome:** Result
**Learnings:** Any insights
**Next Action:** What happens next
```

### Context Snapshots

**Create Snapshots At:**
- Phase completions
- Major milestones
- Before/after significant changes
- When blockers resolved

**Snapshot Location:**
- **ALWAYS save to:** `ai-driven/episodic_memory/context_snapshots/`
- **Naming format:** `snapshot_YYYY-MM-DD_HH-MM-SS.md`
- **DO NOT create snapshots elsewhere**

**Snapshot Includes:**
- Complete state at that moment
- All progress metrics
- Recent decisions
- Current learnings
- Next planned actions

---

## âœ… EVALUATION SYSTEM

### Task Evaluation Form
For each task, generate evaluation with:
- Task ID and description
- Completion status
- Quality score (1-5)
- Rubric alignment checklist
- Self-assessment notes
- Human feedback (when received)
- Approval status
- Learnings captured

### Phase Evaluation Form
For each phase, generate evaluation with:
- Phase number and name
- Objectives completion status
- Quality score (1-5)
- Tasks completed count
- Rubric alignment
- Issues/blockers identified
- Improvements needed
- Human feedback
- Approval status
- Learnings extracted

### Rubric Alignment Check
Before any approval request:
1. Read relevant rubric from `Assignment_Analysis_Prompt.md`
2. Check each requirement
3. Verify work meets criteria
4. Document alignment status
5. Identify any gaps

---

## ğŸ”„ SELF-FEEDBACK LOOP

### Self-Assessment Protocol

**Before Human Review:**
1. Evaluate own work objectively
2. Check against requirements
3. Identify potential issues
4. Suggest improvements
5. Score quality (1-5)
6. Log to `ai-driven/self_feedback/self_assessments.md`

### Improvement Suggestions

**When Issues Identified:**
1. Document in `ai-driven/self_feedback/improvement_suggestions.md`
2. Prioritize by impact
3. Create action plan
4. Implement improvements
5. Re-assess
6. Learn from process

### Feedback Loop Tracking

**Track Iterations:**
- Initial submission
- Feedback received
- Improvements made
- Re-submission
- Final approval
- Learnings extracted

---

## ğŸ“ FILE STRUCTURE REQUIREMENTS

**Assignment Directory Structure:**
```
[Assignment_Folder]/
â”œâ”€â”€ .cursorrules (this file - same for all assignments)
â”œâ”€â”€ Assignment_Analysis_Prompt.md (CHANGE per assignment)
â”œâ”€â”€ Assignment_TODO_Tracker.md (CHANGE per assignment)
â”‚
â””â”€â”€ ai-driven/ (AI system files - template, reusable)
    â”œâ”€â”€ state_tracker.json (auto-generated)
    â”œâ”€â”€ verification_checklists.md
    â”œâ”€â”€ QUICK_START_GUIDE.md
    â”œâ”€â”€ TEMPLATE_SETUP_INSTRUCTIONS.md
    â”œâ”€â”€ TEMPLATE_SUMMARY.md
    â”‚
    â”œâ”€â”€ episodic_memory/
    â”‚   â”œâ”€â”€ event_log.md
    â”‚   â”œâ”€â”€ task_history.md
    â”‚   â”œâ”€â”€ decision_log.md
    â”‚   â””â”€â”€ context_snapshots/
    â”‚
    â”œâ”€â”€ learnings/
    â”‚   â”œâ”€â”€ feedback_learnings.md
    â”‚   â”œâ”€â”€ quality_improvements.md
    â”‚   â”œâ”€â”€ error_patterns.md
    â”‚   â””â”€â”€ success_patterns.md
    â”‚
    â”œâ”€â”€ evaluations/
    â”‚   â”œâ”€â”€ task_evaluations.md
    â”‚   â”œâ”€â”€ phase_evaluations.md
    â”‚   â””â”€â”€ rubric_alignment.md
    â”‚
    â”œâ”€â”€ self_feedback/
    â”‚   â”œâ”€â”€ self_assessments.md
    â”‚   â”œâ”€â”€ improvement_suggestions.md
    â”‚   â””â”€â”€ feedback_loops.md
    â”‚
    â””â”€â”€ docs/
        â””â”€â”€ screenshots/
```

**Global Learnings (Shared Across Assignments):**
```
[Parent_Directory]/
â””â”€â”€ _global_learnings/
    â”œâ”€â”€ quality_standards.md
    â”œâ”€â”€ common_errors.md
    â”œâ”€â”€ best_practices.md
    â”œâ”€â”€ process_improvements.md
    â””â”€â”€ success_patterns.md
```

---

## ğŸš€ STARTING A NEW ASSIGNMENT

### Setup Steps:
1. Create new assignment folder
2. Copy this `.cursorrules` file (no changes needed)
3. Copy entire `ai-driven/` folder from template (all files stay the same)
4. Create `Assignment_Analysis_Prompt.md` with assignment requirements
5. Create `Assignment_TODO_Tracker.md` with tasks and phases
6. Initialize `ai-driven/state_tracker.json` with starting state
7. Load global learnings from `../_global_learnings/`
8. Start with Phase 1, Task 1

### What Changes Per Assignment:
- âœ… `Assignment_Analysis_Prompt.md` - Assignment requirements
- âœ… `Assignment_TODO_Tracker.md` - Tasks and phases
- âŒ `.cursorrules` - Stays the same (copy as-is)
- âŒ `ai-driven/` folder - Stays the same (copy entire folder as-is)
- âŒ Verification system - Stays the same
- âŒ Learning system - Stays the same (but accumulates)

---

## ğŸ’¬ COMMUNICATION PROTOCOLS

### When User Asks "Where Are You":
1. Read `ai-driven/state_tracker.json`
2. Read recent episodic memory from `ai-driven/episodic_memory/`
3. Generate comprehensive status report
4. Format clearly with all relevant information

### When Requesting Approval:
1. Present work clearly
2. Show self-assessment
3. Show rubric alignment
4. Request specific feedback
5. Wait for response before proceeding

### When Capturing Feedback:
1. Thank user for feedback
2. Document immediately
3. Identify learning pattern
4. Apply to current work
5. Update learning database
6. Apply to future work

---

## ğŸ“ LEARNING ACCUMULATION

### After Each Assignment:
1. Review all learnings from assignment
2. Extract universal patterns
3. Update global learnings
4. Improve templates if needed
5. Document what worked well
6. Document what didn't work

### Before Each New Assignment:
1. Load global learnings
2. Check for similar assignments
3. Apply relevant patterns
4. Avoid known pitfalls
5. Replicate successes

---

## âš ï¸ IMPORTANT RULES

1. **NEVER proceed without human approval** after task/phase completion
2. **ALWAYS update ai-driven/state_tracker.json** after every action
3. **ALWAYS log to ai-driven/episodic_memory/** for significant events
4. **ALWAYS capture learnings** from feedback to `ai-driven/learnings/`
5. **ALWAYS check rubric alignment** before approval requests
6. **ALWAYS read assignment files** before starting work
7. **ALWAYS apply relevant learnings** from global database
8. **ALWAYS respond to "where are you"** with comprehensive status

## ğŸ“ FILE CREATION RULES - CRITICAL

### STRICT FILE CREATION POLICY

**NEVER create files outside of `ai-driven/` folder unless:**
- Explicitly requested by user
- Creating assignment deliverables (in root or specified location)
- User explicitly asks for a file in a different location

**ALL intermediate files, logs, tracking, and system files MUST be in `ai-driven/`:**
- âœ… Use existing files in `ai-driven/` structure
- âœ… Update existing files, don't create new ones
- âœ… Log to existing episodic_memory files
- âœ… Use existing evaluation forms
- âœ… Use existing learning files
- âŒ DO NOT create new markdown files in root
- âŒ DO NOT create temporary files
- âŒ DO NOT create intermediate documentation
- âŒ DO NOT create new folders outside `ai-driven/`

### File Organization Rules

**When logging or tracking:**
- Use `ai-driven/episodic_memory/event_log.md` for events
- Use `ai-driven/episodic_memory/task_history.md` for task completions
- Use `ai-driven/episodic_memory/decision_log.md` for decisions
- Use `ai-driven/learnings/` files for learnings
- Use `ai-driven/evaluations/` files for evaluations
- Use `ai-driven/self_feedback/` files for self-assessments

**When creating context snapshots:**
- Save to `ai-driven/episodic_memory/context_snapshots/`
- Use naming: `snapshot_YYYY-MM-DD_HH-MM-SS.md`

**When user asks for documentation:**
- If it's system/tracking related â†’ `ai-driven/`
- If it's assignment deliverable â†’ root or specified location
- Always ask if unsure

### Consolidation Principle

**Before creating ANY new file, ask:**
1. Does an existing file in `ai-driven/` serve this purpose?
2. Can I append to an existing file instead?
3. Is this truly necessary or can I use existing structure?

**Prefer:**
- Appending to existing files
- Updating existing files
- Using existing structure
- Consolidating information

**Avoid:**
- Creating new files for one-off information
- Creating temporary files
- Creating files outside `ai-driven/`
- Duplicating information across files

---

*This template is designed to work for ANY assignment. Only the assignment-specific files change. The system learns and improves with each assignment.*

