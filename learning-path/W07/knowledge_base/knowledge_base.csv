knowledge_id,week_number,week_name,category,item_name,description,learning_objectives,prerequisites,difficulty_level,estimated_time_minutes
KB-W00-001,W00,Core AI Concepts,concept,Tokens and Tokenization,Text split into small units (tokens). Foundation of all LLM processing. Understand BPE subword and character tokenization.,Understand token units|Compare tokenization methods|Analyze token efficiency,None,beginner,45
KB-W00-002,W00,Core AI Concepts,concept,Embeddings,Tokens converted to vectors (numerical representations). Semantic meaning encoded in high-dimensional space.,Convert tokens to vectors|Visualize embedding space|Measure semantic similarity,None,beginner,60
KB-W00-003,W00,Core AI Concepts,concept,Vector Relationships and Attention,How each token/vector relates to every other. Self-attention mechanism computes contextual relationships.,Understand attention mechanism|Visualize attention patterns|Compute attention scores,None,intermediate,75
KB-W00-004,W00,Core AI Concepts,concept,Transformer Layers,Stacked attention + feedforward blocks. Multiple layers apply attention and transformations repeatedly.,Understand layer composition|Trace data through layers|Analyze layer outputs,None,intermediate,60
KB-W00-005,W00,Core AI Concepts,concept,Tensors,Data and weights stored and computed in tensors (multi-dimensional arrays). Core data structure for deep learning.,Manipulate tensor shapes|Understand broadcasting|Perform tensor operations,None,beginner,45
KB-W00-006,W00,Core AI Concepts,concept,Parameters and Weights,Learned numerical values inside tensors updated during training. The knowledge of the model.,Count model parameters|Inspect weight matrices|Understand parameter updates,None,intermediate,60
KB-W00-007,W00,Core AI Concepts,concept,LLM Architecture Overview,Complete picture: Tokens → Embeddings → Attention → Layers → Tensors → Parameters. End-to-end understanding.,Trace full LLM pipeline|Inspect model components|Extract architecture details,None,intermediate,90
KB-W00-008,W00,Core AI Concepts,exercise,Model Inspection Exercise,Retrieve hidden size number of layers attention heads tensor shapes embedding size vocabulary size from any model.,Extract model config|Analyze architecture|Compare model sizes,None,beginner,60
KB-W00-009,W00,Core AI Concepts,exercise,Build Mini GPT from Scratch,Build a real small GPT-style model (10-20M params) from scratch. Implements attention layers and training loop.,Implement transformer blocks|Train from scratch|Generate text,None,advanced,180
KB-W00-010,W00,Core AI Concepts,exercise,Custom Tokenizer Training,Train a BPE tokenizer on custom corpus. Understand vocabulary construction and subword segmentation.,Train BPE tokenizer|Configure vocab size|Test tokenization,None,intermediate,45
KB-W00-011,W00,Core AI Concepts,project,Bloom Taxonomy Educational LLM,Build a tutor that answers using Bloom's Taxonomy levels: remember understand apply analyze evaluate create.,Design Bloom prompts|Generate training data|Build educational RAG,None,advanced,240
KB-W00-012,W00,Core AI Concepts,project,Bloom RAG System,RAG system that retrieves from learning notes and answers in Bloom's Taxonomy format with 6 cognitive levels.,Build note retrieval|Implement Bloom prompt|Ground answers in context,None,advanced,120
KB-W00-013,W00,Core AI Concepts,project,Bloom Dataset Generator,Auto-generate Bloom's Taxonomy training data from notes. Creates instruction dataset for fine-tuning.,Parse learning notes|Generate Q&A pairs|Format for training,None,intermediate,90
KB-W00-014,W00,Core AI Concepts,project,Bloom Evaluation Script,Evaluate Bloom quality: checks for all 6 sections provides human rubric scores measures completeness.,Check section coverage|Score with rubric|Measure quality,None,intermediate,60
KB-W00-015,W00,Core AI Concepts,deployment,Ollama Bloom Tutor Deployment,Deploy Bloom tutor via Ollama Modelfile. Bakes Bloom's Taxonomy prompt into local model.,Create Modelfile|Build Ollama model|Run locally,None,intermediate,30
KB-W01-001,W01,Prompt Engineering,concept,LLM Fundamentals,Understanding how LLMs work: tokenization attention mechanisms and generation strategies. Foundation for building AI applications.,Understand tokenization|Learn attention mechanisms|Explore generation strategies,None,beginner,60
KB-W01-002,W01,Prompt Engineering,concept,Prompt Design Patterns,Common prompt patterns: zero-shot few-shot chain-of-thought and instruction following. Core skill for application builders.,Master zero-shot prompting|Implement few-shot examples|Apply chain-of-thought,None,beginner,45
KB-W01-003,W01,Prompt Engineering,exercise,Prompt Engineering Exercise,Introduction to prompt engineering with Mistral-7B model. Learn system prompts and prompt engineering techniques.,Design effective system prompts|Test prompt variations|Measure output quality,None,beginner,90
KB-W01-004,W01,Prompt Engineering,exercise,Temperature and Sampling,Explore temperature top-p top-k sampling and their effects on generation diversity and quality.,Understand temperature effects|Compare sampling strategies|Tune generation parameters,None,beginner,60
KB-W02-001,W02,RAG Foundations,concept,Data Engineering for RAG,Data pipelines for RAG: ETL processes data quality validation lineage tracking and ingestion patterns.,Build data pipelines|Validate data quality|Track data lineage,W01,intermediate,90
KB-W02-002,W02,RAG Foundations,concept,Embeddings Deep Dive,Understanding embeddings: how they work semantic similarity and choosing embedding models for applications.,Understand vector representations|Calculate similarity scores|Visualize embedding spaces,W01,beginner,75
KB-W02-003,W02,RAG Foundations,concept,Embedding Models Comparison,Compare embedding models: all-MiniLM-L6 vs BGE vs E5. Practical guide for application developers.,Benchmark embedding models|Analyze dimensionality tradeoffs|Select optimal embeddings,W01,intermediate,90
KB-W02-004,W02,RAG Foundations,concept,Chunking Strategies,Document chunking methods: fixed-size recursive semantic and token-aware. Critical for RAG application quality.,Implement chunking methods|Compare chunk quality|Optimize chunk sizes,W01,beginner,60
KB-W02-005,W02,RAG Foundations,exercise,Simple RAG System,Build a simple RAG chatbot using LangChain and FAISS for FAQ-based question answering. First complete AI application.,Build basic RAG pipeline|Implement vector retrieval|Generate contextual responses,W01,beginner,120
KB-W03-001,W03,RAG Production,concept,Retrieval Strategies,Advanced retrieval: hybrid search combining BM25 sparse retrieval with dense embeddings and reranking.,Implement hybrid search|Apply cross-encoder reranking|Optimize retrieval quality,W02,intermediate,90
KB-W03-002,W03,RAG Production,concept,Context Window Management,Handling long contexts: summarization chains map-reduce and context compression techniques.,Manage context limits|Implement summarization|Apply compression techniques,W02,intermediate,75
KB-W03-003,W03,RAG Production,concept,RAG Evaluation Metrics,Understanding RAG metrics: retrieval (MRR NDCG Recall@K) and generation (faithfulness relevance).,Calculate retrieval metrics|Measure generation quality|Interpret evaluation scores,W02,intermediate,60
KB-W03-004,W03,RAG Production,exercise,RAG System with Evaluation,Complete RAG system with model evaluation framework. Production-ready RAG application.,Build complete RAG system|Evaluate multiple models|Rank by composite scores,W01 W02,intermediate,150
KB-W03-005,W03,RAG Production,exercise,Hallucination Detection,Implement hallucination detection: faithfulness scoring factual consistency and citation verification.,Detect hallucinations|Score faithfulness|Verify factual consistency,W02,intermediate,90
KB-W03-006,W03,RAG Production,assignment,GreenTech RAG Assignment,Complete RAG assignment for GreenTech Marketplace customer support. Real-world business application.,Complete all 6 objectives|Build production RAG|Document findings,W01 W02,intermediate,240
KB-W03-007,W03,RAG Production,project,Job Fitment Agent,AI-powered job fitment analysis agent. Analyzes job postings and provides fitment scores with skill gap identification.,Scrape job postings|Analyze skill fitment|Identify skill gaps,W01 W02,advanced,180
KB-W06-001,W06,Safety and Guardrails,concept,LLM Security Fundamentals,Understanding LLM vulnerabilities: prompt injection jailbreaks and data leakage.,Understand attack vectors|Identify vulnerabilities|Plan mitigations,W01,intermediate,60
KB-W06-002,W06,Safety and Guardrails,concept,Content Moderation Strategies,Approaches to content moderation: classification filtering and human-in-the-loop.,Implement classification|Design filters|Plan human review,W01,intermediate,60
KB-W06-003,W06,Safety and Guardrails,exercise,Input Validation Guards,Implement input validation: prompt injection detection PII filtering and input sanitization.,Detect prompt injection|Filter PII|Sanitize inputs,W01,intermediate,90
KB-W06-004,W06,Safety and Guardrails,exercise,Output Validation Guards,Implement output validation: toxicity filtering factuality checking and format enforcement.,Filter toxic content|Check factuality|Enforce output format,W01,intermediate,90
KB-W07-001,W07,AI Agents,concept,Async Patterns for Agents,AsyncIO patterns for concurrent agent execution. Parallel tool calls and non-blocking workflows.,Implement async/await|Run parallel tool calls|Design non-blocking agents,W01,intermediate,75
KB-W07-002,W07,AI Agents,concept,Agent Architecture Patterns,Understanding agent architectures: ReAct function calling and tool use patterns. Core of agentic workflows.,Understand ReAct pattern|Implement function calling|Design tool interfaces,W01,intermediate,75
KB-W07-003,W07,AI Agents,concept,Agent Memory Systems,Memory for agents: buffer memory summary memory vector-backed memory and episodic memory.,Implement memory types|Compare memory strategies|Design memory architecture,W02,intermediate,90
KB-W07-004,W07,AI Agents,concept,Planning and Reasoning,Agent planning: chain-of-thought tree-of-thought and plan-and-execute patterns.,Implement CoT prompting|Apply tree-of-thought|Design planning systems,W01,advanced,90
KB-W07-005,W07,AI Agents,concept,Tool Design Principles,Designing effective tools: API design error handling and tool descriptions for agents.,Design tool interfaces|Handle errors gracefully|Write clear descriptions,W01,intermediate,60
KB-W07-006,W07,AI Agents,exercise,Basic Agent Implementation,Build a basic ReAct agent with tools using LangChain or OpenAI function calling.,Build ReAct agent|Implement tool calling|Test agent behavior,W01,intermediate,120
KB-W07-007,W07,AI Agents,exercise,Multi-Tool Agent,Build an agent with multiple tools: search calculator code execution and file operations.,Integrate multiple tools|Handle tool selection|Manage tool errors,W01,intermediate,150
KB-W07-008,W07,AI Agents,exercise,MCP Integration,Integrate Model Context Protocol (MCP) servers for extended agent capabilities.,Connect MCP servers|Use MCP tools|Build MCP-enabled agent,W01,advanced,120
KB-W07-009,W07,AI Agents,assignment,OpenAI Agent Builder Project,OpenAI Agent Builder project for automating workflows. Demonstrates agentic workflow mastery.,Build production agent|Automate complex workflow|Generate actionable outputs,W03,advanced,300
KB-W08-001,W08,Multimodal AI,concept,Vision-Language Models,Understanding VLMs: architecture training and capabilities of models like BLIP LLaVA and GPT-4V.,Understand VLM architecture|Compare model capabilities|Select appropriate models,W01,intermediate,75
KB-W08-002,W08,Multimodal AI,concept,Audio Processing with LLMs,Speech-to-text text-to-speech and audio understanding with Whisper and similar models.,Process audio input|Generate speech output|Understand audio models,W01,intermediate,60
KB-W08-003,W08,Multimodal AI,concept,Document Understanding,Processing documents: OCR layout analysis and document Q&A with multimodal models.,Extract text from images|Analyze document layout|Answer document questions,W01,intermediate,75
KB-W08-004,W08,Multimodal AI,exercise,Image Captioning,Generate captions for images using vision-language models. Practical multimodal application.,Generate image captions|Fine-tune captioning|Evaluate caption quality,None,beginner,90
KB-W08-005,W08,Multimodal AI,exercise,PDF Q&A System,Question answering system for PDF documents using RAG. Document intelligence application.,Parse PDF documents|Build document RAG|Answer document questions,W02,intermediate,120
KB-W08-006,W08,Multimodal AI,exercise,Speech to Image Pipeline,Convert speech to images using Whisper and Stable Diffusion. Creative multimodal application.,Transcribe speech|Generate images|Build multimodal pipeline,W01,intermediate,150
KB-W09-001,W09,Agentic RAG,concept,Agentic RAG Architecture,Understanding agentic RAG: query routing self-correction and adaptive retrieval. Next-gen RAG applications.,Understand agentic RAG|Design routing logic|Implement self-correction,W03 W07,advanced,90
KB-W09-002,W09,Agentic RAG,concept,Query Understanding,Advanced query processing: decomposition rewriting and intent classification for RAG.,Decompose complex queries|Rewrite for retrieval|Classify query intent,W03,intermediate,75
KB-W09-003,W09,Agentic RAG,concept,Retrieval Agents,Building retrieval agents: when to retrieve what to retrieve and how to combine results.,Build retrieval agents|Implement adaptive retrieval|Combine multiple sources,W03 W07,advanced,90
KB-W09-004,W09,Agentic RAG,exercise,Agentic RAG with LlamaIndex,Build agentic RAG systems with LlamaIndex framework including query routing and tool calling.,Build with LlamaIndex|Implement query routing|Add tool calling,W03,advanced,180
KB-W09-005,W09,Agentic RAG,exercise,Self-Correcting RAG,Implement self-correcting RAG with hallucination detection and query refinement loops.,Detect retrieval failures|Implement correction loops|Refine queries,W03,advanced,150
KB-W10-001,W10,Multi-Agent Systems,concept,Multi-Agent Architecture,Designing multi-agent systems: coordination communication and task delegation.,Design multi-agent architectures|Implement coordination|Handle communication,W07 W09,advanced,90
KB-W10-002,W10,Multi-Agent Systems,concept,Agent Orchestration Patterns,Orchestration patterns: supervisor hierarchical and collaborative agent coordination.,Implement supervisor pattern|Design hierarchies|Enable collaboration,W07,advanced,90
KB-W10-003,W10,Multi-Agent Systems,concept,State Management for Agents,Managing state in agent systems: checkpointing rollback and persistent state.,Implement checkpointing|Handle rollback|Persist agent state,W07,advanced,75
KB-W10-004,W10,Multi-Agent Systems,exercise,Advanced Agentic RAG,Advanced agentic RAG with multi-document agents and complex reasoning.,Build multi-document agents|Implement complex reasoning|Handle advanced queries,W09,advanced,180
KB-W10-005,W10,Multi-Agent Systems,exercise,Multi-Agent RAG System,Build multi-agent RAG with specialized retrieval analysis and synthesis agents.,Design specialized agents|Coordinate retrieval|Synthesize results,W07 W09,advanced,180
KB-W10-006,W10,Multi-Agent Systems,project,Research Assistant System,Multi-agent research assistant that searches analyzes and synthesizes information autonomously.,Build autonomous researcher|Coordinate multiple agents|Generate research reports,W07 W09,advanced,300
KB-W02-006,W02,Vector Infrastructure,concept,Vector Database Fundamentals,Introduction to vector databases: indexing algorithms ANN search and FAISS internals. Core inference infrastructure.,Understand ANN algorithms|Configure FAISS indices|Optimize search parameters,W01,intermediate,75
KB-W02-007,W02,Vector Infrastructure,exercise,Vector DB Comparison,Compare vector databases: FAISS vs ChromaDB vs Qdrant. Benchmark performance for inference optimization.,Benchmark vector databases|Compare query latencies|Evaluate feature sets,W01,intermediate,90
KB-W05-001,W05,Inference Optimization,concept,Quantization Fundamentals,Understanding quantization: INT8 INT4 GGUF AWQ and GPTQ formats. Critical for inference cost reduction.,Understand quantization types|Compare format tradeoffs|Select appropriate format,W01,intermediate,75
KB-W05-002,W05,Inference Optimization,concept,Inference Optimization Techniques,Optimizing LLM inference: KV caching batching speculative decoding and continuous batching.,Understand KV caching|Implement batching|Apply optimization techniques,W01,advanced,90
KB-W05-003,W05,Inference Optimization,concept,Cost Optimization Strategies,Token budgeting caching strategies model routing and cost-aware architecture design.,Calculate token costs|Implement caching|Design cost-aware systems,W01,intermediate,60
KB-W05-004,W05,Inference Optimization,concept,Inference Throughput Analysis,Understanding throughput: tokens per second batching efficiency and latency vs throughput tradeoffs.,Measure throughput|Analyze batching efficiency|Optimize for workload,W01,intermediate,60
KB-W05-005,W05,Inference Optimization,exercise,Model Quantization,Quantize models using GGUF and AWQ. Measure latency and quality tradeoffs for production deployment.,Quantize models|Benchmark performance|Analyze quality impact,W01,intermediate,120
KB-W05-006,W05,Inference Optimization,exercise,Inference Server Setup,Set up vLLM or TGI for production inference with benchmarking. Core infrastructure skill.,Deploy inference server|Configure optimization|Benchmark throughput,W01,advanced,150
KB-W05-007,W05,Inference Optimization,exercise,Latency Profiling,Profile and optimize LLM pipeline latency: tokenization inference and decoding.,Profile pipeline stages|Identify bottlenecks|Optimize latency,W01,advanced,90
KB-W05-008,W05,Inference Optimization,exercise,Streaming with SSE,Implement Server-Sent Events for streaming LLM responses. Real-time token-by-token output to clients.,Implement SSE endpoints|Stream LLM tokens|Handle client connections,W01,intermediate,90
KB-W05-009,W05,Inference Optimization,exercise,WebSocket Real-time AI,Build bidirectional real-time AI communication with WebSockets. Interactive agent conversations.,Implement WebSocket server|Handle bidirectional messages|Build interactive AI,W01,intermediate,120
KB-W05-010,W05,Inference Optimization,exercise,Token Cost Calculator,Build token cost calculator and optimizer for production LLM applications.,Calculate token costs|Optimize prompts|Budget for production,W01,intermediate,60
KB-W05-011,W05,Inference Optimization,project,Inference Benchmark Dashboard,Interactive dashboard comparing inference providers: latency cost and quality metrics.,Benchmark providers|Visualize metrics|Compare cost-performance,W01,advanced,180
KB-W11-001,W11,Reinforcement Fine-Tuning,concept,GRPO Fundamentals,Understanding Group Relative Policy Optimization (GRPO): reinforcement learning fine-tuning for LLMs. Alternative to RLHF for aligning models.,Understand GRPO algorithm|Compare to RLHF|Learn policy optimization,W04,advanced,90
KB-W11-002,W11,Reinforcement Fine-Tuning,concept,Reward Functions,Designing reward functions for reinforcement learning: explicit rewards implicit rewards and reward shaping.,Design reward functions|Implement reward shaping|Evaluate reward quality,W04,intermediate,75
KB-W11-003,W11,Reinforcement Fine-Tuning,concept,LLM as Judge,Using LLMs as reward models: LLM-as-a-judge pattern for evaluating model outputs without explicit reward functions.,Implement LLM judge|Design evaluation prompts|Use for reward signals,W04,intermediate,90
KB-W11-004,W11,Reinforcement Fine-Tuning,concept,Reward Hacking,Understanding reward hacking: when models optimize for reward signal instead of intended behavior. Mitigation strategies.,Identify reward hacking|Design robust rewards|Mitigate gaming,W04,advanced,60
KB-W11-005,W11,Reinforcement Fine-Tuning,concept,GRPO Loss Calculation,Calculating loss in GRPO: policy gradient computation group relative comparisons and optimization objective.,Calculate GRPO loss|Implement policy gradients|Optimize objective,W04,advanced,90
KB-W11-006,W11,Reinforcement Fine-Tuning,exercise,Wordle Master with GRPO,Complete GRPO training project: train an LLM to master Wordle using reinforcement fine-tuning with GRPO algorithm.,Implement GRPO training|Train Wordle model|Evaluate performance,W04,advanced,240
KB-W11-007,W11,Reinforcement Fine-Tuning,assignment,GRPO Group Task,Group assignment: practice reinforcement fine-tuning with GRPO by modifying DeepLearning.AI lessons. Complete Wordle training project.,Complete GRPO lessons|Modify training code|Train Wordle model,W04,advanced,300
KB-W04-001,W04,Fine-tuning,concept,Transfer Learning for LLMs,Understanding transfer learning: pre-training vs fine-tuning when to fine-tune vs use RAG.,Understand transfer learning|Compare fine-tuning vs RAG|Choose appropriate approach,W01,intermediate,60
KB-W04-002,W04,Fine-tuning,concept,PEFT Techniques Overview,Parameter-efficient fine-tuning: LoRA QLoRA adapters and prefix tuning explained.,Understand PEFT methods|Compare adapter approaches|Select optimal technique,W01,intermediate,75
KB-W04-003,W04,Fine-tuning,concept,Dataset Preparation,Preparing datasets for fine-tuning: formatting cleaning and creating instruction datasets.,Format training data|Clean datasets|Create instruction sets,W01,beginner,60
KB-W04-004,W04,Fine-tuning,concept,Training Dynamics,Understanding training: loss curves learning rates and convergence analysis.,Analyze loss curves|Tune learning rates|Monitor convergence,W01,intermediate,75
KB-W04-005,W04,Fine-tuning,exercise,LoRA Fine-tuning,Fine-tune a model using LoRA on a custom dataset. Understand rank alpha and target modules.,Configure LoRA parameters|Fine-tune on custom data|Evaluate improvements,W01,intermediate,180
KB-W04-006,W04,Fine-tuning,exercise,QLoRA Fine-tuning,Memory-efficient fine-tuning with QLoRA using 4-bit quantization.,Apply 4-bit quantization|Configure QLoRA|Train on limited hardware,W01,intermediate,180
KB-W04-007,W04,Fine-tuning,exercise,Fine-tuning vs RAG Analysis,Empirical comparison: when fine-tuning beats RAG and vice versa with cost-benefit analysis.,Compare approaches empirically|Analyze cost-benefit|Document tradeoffs,W02 W03,advanced,120
KB-W04-008,W04,Fine-tuning,concept,Evaluation for Fine-tuned Models,Evaluating fine-tuned models: benchmark selection metrics and A/B testing.,Select benchmarks|Compute metrics|Design A/B tests,W01,intermediate,75
KB-W04-009,W04,Fine-tuning,project,Domain-Specific Fine-tuning,Fine-tune a model for a specific domain with full evaluation pipeline.,Fine-tune for domain|Evaluate thoroughly|Document improvements,W01,advanced,360
KB-W04-010,W04,Fine-tuning,concept,Constitutional AI Principles,Understanding constitutional AI: self-critique RLHF and alignment techniques.,Understand RLHF|Learn constitutional AI|Apply alignment principles,W01,advanced,75
KB-W04-011,W04,Fine-tuning,concept,Open vs Closed Models,Comparing open-source vs closed models: capabilities costs and strategic considerations.,Compare model types|Analyze costs|Make strategic decisions,W01,intermediate,60
KB-N/A-001,N/A,Blog,article,RAG vs Fine-tuning Decision Framework,Technical blog post on when to use RAG vs fine-tuning with real-world examples.,Articulate tradeoffs|Provide framework|Share examples,W03 W04,advanced,180
KB-N/A-002,N/A,Blog,article,Agentic Workflows in Production,Article on deploying agentic workflows: lessons learned and best practices.,Share production insights|Document patterns|Provide guidance,W07 W09 W10,advanced,180
KB-N/A-003,N/A,Blog,article,The Three Layers of AI,Article explaining AI stack layers based on Andrew Ng's framework with portfolio perspective.,Explain AI stack|Connect to portfolio|Provide perspective,W01-W11,intermediate,120
KB-N/A-004,N/A,Blog,article,LLM Inference Economics,Deep dive into inference costs throughput and optimization strategies for practitioners.,Analyze economics|Provide optimization guide|Share data,W05 W11,advanced,180
KB-N/A-005,N/A,Blog,article,Product Case Study - Job Fitment Agent,User research to AI solution case study. Demonstrates user empathy and product thinking.,Document user needs|Show solution process|Measure outcomes,W03 W07,intermediate,120
KB-N/A-006,N/A,Blog,article,Product Case Study - GreenTech RAG,End-to-end case study of building customer support RAG. From problem to production.,Document business problem|Show technical solution|Present results,W03,intermediate,120
KB-N/A-007,N/A,Blog,article,Core LLM Concepts Explained,Educational article: Tokens Embeddings Attention Layers Tensors Parameters - the complete LLM pipeline.,Explain fundamentals|Use clear analogies|Provide code examples,W00,intermediate,120
KB-N/A-008,N/A,Talks,presentation,AI Portfolio Overview,Presentation deck showcasing AI portfolio using three-layer framework.,Create compelling narrative|Showcase projects|Demonstrate expertise,W00-W11,intermediate,120
