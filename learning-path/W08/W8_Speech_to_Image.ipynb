{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4Bv0wQtM9bG"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/oviya-raja/ist-402/blob/main/learning-path/W08/W8_Speech_to_Image.ipynb)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKeCpTY5M9bG"
      },
      "source": [
        "# Speech-to-Image Generator\n",
        "\n",
        "## Overview\n",
        "This notebook implements an end-to-end multimodal pipeline that converts spoken descriptions into AI-generated images.\n",
        "\n",
        "## Architecture\n",
        "1. **Speech-to-Text**: Transcribe audio using OpenAI Whisper\n",
        "2. **Text-to-Image**: Generate images from text using Stable Diffusion v1.5\n",
        "\n",
        "## Pipeline Flow\n",
        "```\n",
        "Audio File ‚Üí Whisper (Transcription) ‚Üí Text Prompt ‚Üí\n",
        "Stable Diffusion (Generation) ‚Üí Generated Image\n",
        "```\n",
        "\n",
        "Alternative: Direct text input bypasses transcription stage.\n",
        "\n",
        "## Features\n",
        "- **Dual Input Methods**: Upload audio files OR type text directly\n",
        "- **High-Quality Transcription**: OpenAI Whisper for accurate speech recognition\n",
        "- **Creative Image Generation**: Stable Diffusion v1.5 for diverse image creation\n",
        "- **Adjustable Settings**: Control quality (inference steps) and prompt adherence (guidance scale)\n",
        "- **User-Friendly Interface**: Clear progress indicators and image download\n",
        "\n",
        "## Usage\n",
        "1. Run the cell below to install dependencies and launch the app\n",
        "2. Choose input method:\n",
        "   - **Audio Tab**: Upload audio file (WAV, MP3, M4A, FLAC) and transcribe\n",
        "   - **Text Tab**: Type your image description directly\n",
        "3. Adjust quality settings (optional)\n",
        "4. Click \"Generate Image\" to create your artwork\n",
        "\n",
        "## Technical Stack\n",
        "- **Speech Recognition**: OpenAI Whisper (tiny variant)\n",
        "- **Image Generation**: Stable Diffusion v1.5 (runwayml)\n",
        "- **UI Framework**: Streamlit\n",
        "- **Deep Learning**: PyTorch, Transformers, Diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTgyjtqo7ggh",
        "outputId": "bbf9ddeb-c3b5-4aae-fd40-0db5ce5c74d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Cleaning up existing processes...\n",
            "‚úÖ Cleanup complete\n",
            "üì¶ Installing packages (2-3 minutes)...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Packages installed!\n",
            "‚úÖ app.py generated successfully\n",
            "üßπ Killing any ngrok processes...\n",
            "‚úÖ ngrok processes killed\n",
            "‚úÖ Loaded ngrok token from Google Colab userdata\n",
            "‚úÖ ngrok token configured successfully\n",
            "üîå Disconnecting any existing tunnels...\n",
            "‚úÖ All tunnels disconnected\n",
            "\n",
            "üöÄ Starting Streamlit...\n",
            "‚úÖ Streamlit started!\n",
            "\n",
            "üåê Creating public URL with ngrok...\n",
            "\n",
            "============================================================\n",
            "‚úÖ SUCCESS! Your app is running!\n",
            "============================================================\n",
            "\n",
            "üåê Public URL (share this):\n",
            "   NgrokTunnel: \"https://unrivalable-lenna-soothfastly.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "\n",
            "üè† Local URL:\n",
            "   http://localhost:8501\n",
            "\n",
            "üìå Tips:\n",
            "   ‚Ä¢ Keep this notebook running\n",
            "   ‚Ä¢ First image generation takes longer (loading models)\n",
            "   ‚Ä¢ Use short, clear voice prompts\n",
            "   ‚Ä¢ CPU mode works but is slower than GPU\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "#  Audio-to-Image Generator ‚Äî FIXED VERSION\n",
        "#  Run this entire cell in Google Colab\n",
        "# =====================================================\n",
        "\n",
        "# ==================== STEP 1: Early Cleanup ====================\n",
        "print(\"üßπ Cleaning up existing processes...\")\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "try:\n",
        "    subprocess.run([\"pkill\", \"-f\", \"streamlit\"], capture_output=True, timeout=5)\n",
        "    os.system('pkill -9 ngrok 2>/dev/null || true')\n",
        "    os.system('killall ngrok 2>/dev/null || true')\n",
        "    time.sleep(1)\n",
        "    print(\"‚úÖ Cleanup complete\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# ==================== STEP 2: Install Packages ====================\n",
        "print(\"üì¶ Installing packages (2-3 minutes)...\")\n",
        "%pip install -q \"transformers>=4.35.0\" \"diffusers>=0.24.0\" accelerate streamlit soundfile torch torchvision pyngrok python-dotenv requests==2.32.4\n",
        "print(\"‚úÖ Packages installed!\")\n",
        "\n",
        "# ==================== STEP 3: Create Streamlit App ====================\n",
        "app_code = '''\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import time\n",
        "\n",
        "# Config\n",
        "st.set_page_config(page_title=\"üéôÔ∏è Audio-to-Image\", layout=\"centered\")\n",
        "\n",
        "# ==================== Load Models ====================\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    \"\"\"\n",
        "    Load both Whisper (speech-to-text) and Stable Diffusion (text-to-image) models.\n",
        "    Models are cached to avoid reloading on every interaction.\n",
        "    First run takes 3-5 minutes to download models.\n",
        "    \"\"\"\n",
        "    st.info(\"Loading AI models... (first run takes 3-5 minutes)\")\n",
        "\n",
        "    # Whisper for speech-to-text\n",
        "    whisper = pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=\"openai/whisper-tiny\",\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    )\n",
        "\n",
        "    # Stable Diffusion for image generation\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    sd = StableDiffusionPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "        safety_checker=None\n",
        "    ).to(device)\n",
        "\n",
        "    if device == \"cuda\":\n",
        "        sd.enable_attention_slicing()\n",
        "\n",
        "    return whisper, sd\n",
        "\n",
        "whisper_model, sd_model = load_models()\n",
        "\n",
        "# ==================== UI ====================\n",
        "st.title(\"üéôÔ∏è Audio-to-Image Generator\")\n",
        "st.markdown(\"Transform your voice into stunning AI-generated images!\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Input methods\n",
        "tab1, tab2 = st.tabs([\"üé§ Upload Audio\", \"‚úçÔ∏è Type Text\"])\n",
        "\n",
        "prompt_text = None\n",
        "\n",
        "with tab1:\n",
        "    st.write(\"Upload an audio file with your image description\")\n",
        "    audio_file = st.file_uploader(\n",
        "        \"Choose audio file\",\n",
        "        type=[\"wav\", \"mp3\", \"m4a\", \"flac\"],\n",
        "        help=\"Speak clearly: \\'A beautiful sunset over mountains\\'\")\n",
        "\n",
        "    if audio_file:\n",
        "        st.audio(audio_file)\n",
        "\n",
        "        if st.button(\"üéß Transcribe Audio\", type=\"primary\"):\n",
        "            with st.spinner(\"Converting speech to text...\"):\n",
        "                with open(\"temp_audio.wav\", \"wb\") as f:\n",
        "                    f.write(audio_file.read())\n",
        "                result = whisper_model(\"temp_audio.wav\")\n",
        "                prompt_text = result[\"text\"]\n",
        "                st.success(f\"‚úÖ Transcription: **{prompt_text}**\")\n",
        "                st.session_state.prompt = prompt_text\n",
        "\n",
        "with tab2:\n",
        "    manual_prompt = st.text_area(\n",
        "        \"Describe the image you want to generate:\",\n",
        "        placeholder=\"Example: A serene lake surrounded by autumn trees at sunset\",\n",
        "        height=100\n",
        "    )\n",
        "    if manual_prompt:\n",
        "        st.session_state.prompt = manual_prompt\n",
        "\n",
        "# Settings\n",
        "with st.expander(\"‚öôÔ∏è Advanced Settings\"):\n",
        "    col1, col2 = st.columns(2)\n",
        "    steps = col1.slider(\"Quality (inference steps)\", 10, 50, 25,\n",
        "                       help=\"More steps = better quality but slower\")\n",
        "    guidance = col2.slider(\"Prompt strength\", 5.0, 15.0, 7.5,\n",
        "                          help=\"Higher = follows prompt more closely\")\n",
        "\n",
        "# Generate button\n",
        "st.markdown(\"---\")\n",
        "if st.button(\"üé® Generate Image\", type=\"primary\", use_container_width=True):\n",
        "    final_prompt = st.session_state.get(\\'prompt\\', None)\n",
        "\n",
        "    if not final_prompt:\n",
        "        st.error(\"‚ùå Please provide audio or text first!\")\n",
        "        st.stop()\n",
        "\n",
        "    st.info(f\"üé® Generating image from: **{final_prompt}**\")\n",
        "    st.write(\"This may take 30 seconds to 3 minutes depending on your GPU...\")\n",
        "\n",
        "    progress_bar = st.progress(0)\n",
        "    start_time = time.time()\n",
        "\n",
        "    with st.spinner(\"Creating your masterpiece...\"):\n",
        "        try:\n",
        "            image = sd_model(\n",
        "                prompt=final_prompt,\n",
        "                num_inference_steps=steps,\n",
        "                guidance_scale=guidance,\n",
        "                height=512,\n",
        "                width=512\n",
        "            ).images[0]\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            progress_bar.progress(100)\n",
        "\n",
        "            st.success(f\"‚úÖ Generated in {elapsed:.1f} seconds!\")\n",
        "            st.image(image, caption=final_prompt)\n",
        "\n",
        "            image.save(\"generated_image.png\")\n",
        "            with open(\"generated_image.png\", \"rb\") as f:\n",
        "                st.download_button(\n",
        "                    \"üíæ Download Image\",\n",
        "                    data=f,\n",
        "                    file_name=f\"ai_art_{int(time.time())}.png\",\n",
        "                    mime=\"image/png\",\n",
        "                    use_container_width=True\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"‚ùå Generation failed: {str(e)}\")\n",
        "            st.info(\"Try simplifying your prompt or reducing quality settings\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"üîä Powered by OpenAI Whisper + Stable Diffusion v1.5\")\n",
        "device_info = \"üöÄ GPU Accelerated\" if torch.cuda.is_available() else \"üê¢ CPU Mode (slower)\"\n",
        "st.caption(device_info)\n",
        "'''\n",
        "\n",
        "# Write app.py\n",
        "try:\n",
        "    with open(\"app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(app_code)\n",
        "    print(\"‚úÖ app.py generated successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to write app.py: {e}\")\n",
        "    raise\n",
        "\n",
        "# ==================== STEP 4: Setup ngrok ====================\n",
        "from pyngrok import ngrok\n",
        "import sys\n",
        "\n",
        "# Kill ngrok again after import\n",
        "print(\"üßπ Killing any ngrok processes...\")\n",
        "try:\n",
        "    ngrok.kill()\n",
        "    time.sleep(1)\n",
        "    print(\"‚úÖ ngrok processes killed\")\n",
        "except Exception as e:\n",
        "    print(f\"   Note: {e}\")\n",
        "\n",
        "# Load ngrok token from environment variables\n",
        "NGROK_TOKEN = None\n",
        "\n",
        "# Try Google Colab first\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    NGROK_TOKEN = userdata.get('NGROK_AUTHTOKEN')\n",
        "    if NGROK_TOKEN:\n",
        "        print(\"‚úÖ Loaded ngrok token from Google Colab userdata\")\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# Try .env file if not found\n",
        "if not NGROK_TOKEN:\n",
        "    try:\n",
        "        from dotenv import load_dotenv\n",
        "        load_dotenv()\n",
        "        NGROK_TOKEN = os.getenv('NGROK_AUTHTOKEN')\n",
        "        if NGROK_TOKEN:\n",
        "            print(\"‚úÖ Loaded ngrok token from .env file\")\n",
        "    except ImportError:\n",
        "        pass\n",
        "\n",
        "# Fallback to environment variable\n",
        "if not NGROK_TOKEN:\n",
        "    NGROK_TOKEN = os.getenv('NGROK_AUTHTOKEN')\n",
        "    if NGROK_TOKEN:\n",
        "        print(\"‚úÖ Loaded ngrok token from environment variable\")\n",
        "\n",
        "# Check if token was found\n",
        "if not NGROK_TOKEN:\n",
        "    print(\"\\n‚ùå ERROR: NGROK_AUTHTOKEN not found!\")\n",
        "    print(\"\\nüìù How to set it in Google Colab:\")\n",
        "    print(\"   1. Click the üîë key icon in the left sidebar\")\n",
        "    print(\"   2. Add new secret: NGROK_AUTHTOKEN\")\n",
        "    print(\"   3. Paste your token from: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "    print(\"   4. Toggle 'Notebook access' ON\")\n",
        "    print(\"\\n   For Local (Jupyter/VS Code):\")\n",
        "    print(\"   1. Create a .env file in this directory\")\n",
        "    print(\"   2. Add: NGROK_AUTHTOKEN=your_token_here\")\n",
        "    raise SystemExit(\"NGROK_AUTHTOKEN not configured\")\n",
        "\n",
        "# Configure ngrok with token\n",
        "try:\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "    print(\"‚úÖ ngrok token configured successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Warning: Could not set ngrok token: {e}\")\n",
        "\n",
        "# Disconnect any existing tunnels\n",
        "print(\"üîå Disconnecting any existing tunnels...\")\n",
        "try:\n",
        "    tunnels = ngrok.get_tunnels()\n",
        "    for tunnel in tunnels:\n",
        "        ngrok.disconnect(tunnel.public_url)\n",
        "        print(f\"   Disconnected: {tunnel.public_url}\")\n",
        "    if tunnels:\n",
        "        time.sleep(2)\n",
        "    print(\"‚úÖ All tunnels disconnected\")\n",
        "except Exception as e:\n",
        "    print(f\"   Note: {e}\")\n",
        "\n",
        "# ==================== STEP 5: Start Streamlit ====================\n",
        "# Kill any existing streamlit on port 8501\n",
        "try:\n",
        "    os.system('lsof -ti:8501 | xargs kill -9 2>/dev/null || true')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print(\"\\nüöÄ Starting Streamlit...\")\n",
        "try:\n",
        "    subprocess.Popen(\n",
        "        [\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"],\n",
        "        stdout=subprocess.DEVNULL,\n",
        "        stderr=subprocess.DEVNULL,\n",
        "        start_new_session=True\n",
        "    )\n",
        "    time.sleep(5)\n",
        "    print(\"‚úÖ Streamlit started!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error starting Streamlit: {e}\")\n",
        "    print(\"   You can start it manually with: streamlit run app.py\")\n",
        "\n",
        "# ==================== STEP 6: Create ngrok Tunnel ====================\n",
        "print(\"\\nüåê Creating public URL with ngrok...\")\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ SUCCESS! Your app is running!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nüåê Public URL (share this):\")\n",
        "    print(f\"   {public_url}\")\n",
        "    print(f\"\\nüè† Local URL:\")\n",
        "    print(f\"   http://localhost:8501\")\n",
        "    print(f\"\\nüìå Tips:\")\n",
        "    print(f\"   ‚Ä¢ Keep this notebook running\")\n",
        "    print(f\"   ‚Ä¢ First image generation takes longer (loading models)\")\n",
        "    print(f\"   ‚Ä¢ Use short, clear voice prompts\")\n",
        "    print(f\"   ‚Ä¢ CPU mode works but is slower than GPU\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "except Exception as e:\n",
        "    error_msg = str(e)\n",
        "    print(f\"\\n‚ö†Ô∏è Could not create ngrok tunnel: {e}\")\n",
        "\n",
        "    # ERR_NGROK_108: 3 session limit\n",
        "    if \"ERR_NGROK_108\" in error_msg or \"3 simultaneous\" in error_msg or \"agent sessions\" in error_msg:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üí° ISSUE: ngrok free account limit (3 sessions)\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"\\n   These sessions are on OTHER machines, not this one.\")\n",
        "        print(\"\\nüîß HOW TO FIX:\")\n",
        "        print(\"   1. Go to: https://dashboard.ngrok.com/agents\")\n",
        "        print(\"   2. Click 'Disconnect' on ALL active sessions\")\n",
        "        print(\"   3. Wait 10 seconds\")\n",
        "        print(\"   4. Re-run this cell\")\n",
        "\n",
        "    # ERR_NGROK_334: Endpoint already online\n",
        "    elif \"ERR_NGROK_334\" in error_msg or \"already online\" in error_msg:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üí° ISSUE: ngrok endpoint already registered\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"\\n   A previous session didn't close properly.\")\n",
        "        print(\"\\nüîß HOW TO FIX:\")\n",
        "        print(\"   1. Go to: https://dashboard.ngrok.com/agents\")\n",
        "        print(\"   2. Click 'Disconnect' on ALL active sessions\")\n",
        "        print(\"   3. Wait 30 seconds\")\n",
        "        print(\"   4. Runtime ‚Üí Restart runtime\")\n",
        "        print(\"   5. Re-run this cell\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nüîß Troubleshooting:\")\n",
        "        print(\"   1. Check your ngrok token is correct\")\n",
        "        print(\"   2. Try: Runtime ‚Üí Restart runtime\")\n",
        "        print(\"   3. Re-run this cell\")\n",
        "\n",
        "    print(\"\\nüìå App is still running locally at: http://localhost:8501\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itR7uty3M9bI"
      },
      "source": [
        "## Example Usage\n",
        "\n",
        "### Method 1: Audio Input\n",
        "1. Record or upload an audio file describing your desired image\n",
        "2. Supported formats: WAV, MP3, M4A, FLAC\n",
        "3. Click \"Transcribe Audio\" to convert speech to text\n",
        "4. Review the transcription\n",
        "5. Click \"Generate Image\" to create the image\n",
        "\n",
        "**Example Audio Prompts:**\n",
        "- \"A serene lake surrounded by autumn trees at sunset\"\n",
        "- \"A futuristic cityscape at night with neon lights\"\n",
        "- \"A cozy coffee shop with warm lighting\"\n",
        "\n",
        "### Method 2: Direct Text Input\n",
        "1. Type your image description directly\n",
        "2. Be descriptive for better results\n",
        "3. Click \"Generate Image\"\n",
        "\n",
        "**Example Text Prompts:**\n",
        "- \"A beautiful sunset over mountains with trees in the foreground\"\n",
        "- \"A modern minimalist living room with large windows\"\n",
        "- \"A vintage typewriter on a wooden desk with books\"\n",
        "\n",
        "### Tips for Best Results\n",
        "- **Be Descriptive**: Include details about colors, mood, style, composition\n",
        "- **Quality Settings**:\n",
        "  - More inference steps = higher quality but slower (25-50 recommended)\n",
        "  - Higher guidance scale = follows prompt more closely (7.5-10 recommended)\n",
        "- **Generation Time**: First generation takes longer (model loading), subsequent ones are faster\n",
        "- **GPU vs CPU**: GPU is 5-10x faster; CPU works but is slower"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}