{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/oviya-raja/ist-402/blob/main/learning-path/W09/W9_Building_Agentic_RAG_LlamaIndex_3_4.ipynb)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bqVkxISRAGy"
      },
      "source": [
        "# Building Agentic RAG with LlamaIndex - Complete Notebook Content\n",
        "\n",
        "This notebook contains all lessons from the course on building agentic RAG systems using LlamaIndex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVenqsSbRJGa"
      },
      "source": [
        "Setup and Installation\n",
        "First, let's install the required packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3m9sre_RQoS"
      },
      "source": [
        "# Setup and Installation\n",
        "First, let's install the required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk2nfXE6RFva",
        "outputId": "a30ddc7a-983e-4ef6-b7dd-9a452247100c"
      },
      "source": [
        "%pip install --upgrade pip\n",
        "%pip install llama-index\n",
        "%pip install llama-index-llms-openai\n",
        "%pip install llama-index-embeddings-openai\n",
        "%pip install nest-asyncio\n",
        "%pip install openai\n",
        "%pip install python-dotenv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (25.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: llama-index in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (0.14.10)\n",
            "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index) (0.5.3)\n",
            "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.10 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index) (0.14.10)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index) (0.9.4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index) (0.6.11)\n",
            "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index) (0.5.5)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index) (3.9.2)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (3.13.2)\n",
            "Requirement already satisfied: aiosqlite in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.22.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2025.12.0)\n",
            "Requirement already satisfied: httpx in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.11.5)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (3.6.1)\n",
            "Requirement already satisfied: numpy in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.3.5)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (12.0.0)\n",
            "Requirement already satisfied: platformdirs in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (4.5.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.12.5)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.32.5)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.0.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.17.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.22.0)\n",
            "Requirement already satisfied: griffe in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.15.0)\n",
            "Requirement already satisfied: jinja2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.1.6)\n",
            "Requirement already satisfied: openai>=1.1.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (2.8.1)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.14.3)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<2.3.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.3)\n",
            "Requirement already satisfied: pypdf<7,>=6.1.3 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.4.2)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: soupsieve>=1.6.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (3.11)\n",
            "Requirement already satisfied: certifi in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.10->llama-index) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.4.2)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.54 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: click<9,>=8.1.7 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.3.1)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.2.1)\n",
            "Requirement already satisfied: joblib in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (2025.11.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.6.2)\n",
            "Requirement already satisfied: greenlet>=1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.10->llama-index) (25.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.0.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: llama-index-llms-openai in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (0.6.11)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.14.5 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-llms-openai) (0.14.10)\n",
            "Requirement already satisfied: openai<3,>=1.108.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-llms-openai) (2.8.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (3.13.2)\n",
            "Requirement already satisfied: aiosqlite in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (0.22.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2025.12.0)\n",
            "Requirement already satisfied: httpx in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2.11.5)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (3.6.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (3.9.2)\n",
            "Requirement already satisfied: numpy in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2.3.5)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (12.0.0)\n",
            "Requirement already satisfied: platformdirs in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (4.5.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2.12.5)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2.32.5)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2.0.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.17.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.22.0)\n",
            "Requirement already satisfied: griffe in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.15.0)\n",
            "Requirement already satisfied: jinja2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (3.1.6)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai<3,>=1.108.1->llama-index-llms-openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai<3,>=1.108.1->llama-index-llms-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai<3,>=1.108.1->llama-index-llms-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai<3,>=1.108.1->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<3,>=1.108.1->llama-index-llms-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (0.4.2)\n",
            "Requirement already satisfied: click in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (8.3.1)\n",
            "Requirement already satisfied: joblib in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2025.11.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (2.6.2)\n",
            "Requirement already satisfied: greenlet>=1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (3.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (25.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-openai) (3.0.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: llama-index-embeddings-openai in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (0.5.1)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-embeddings-openai) (0.14.10)\n",
            "Requirement already satisfied: openai>=1.1.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-embeddings-openai) (2.8.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (3.13.2)\n",
            "Requirement already satisfied: aiosqlite in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (0.22.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2025.12.0)\n",
            "Requirement already satisfied: httpx in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2.11.5)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (3.6.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (3.9.2)\n",
            "Requirement already satisfied: numpy in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2.3.5)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (12.0.0)\n",
            "Requirement already satisfied: platformdirs in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (4.5.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2.12.5)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2.32.5)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2.0.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.17.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.22.0)\n",
            "Requirement already satisfied: griffe in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.15.0)\n",
            "Requirement already satisfied: jinja2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (3.1.6)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (3.11)\n",
            "Requirement already satisfied: click in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (8.3.1)\n",
            "Requirement already satisfied: joblib in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2025.11.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (2.6.2)\n",
            "Requirement already satisfied: greenlet>=1 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (3.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (25.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-openai) (3.0.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: nest-asyncio in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (1.6.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: openai in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (2.8.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai) (2.12.5)\n",
            "Requirement already satisfied: sniffio in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: python-dotenv in /Users/rajasoun/workspace/personal/oviya/ist-402/learning-path/W07/.venv/lib/python3.12/site-packages (1.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSJABWx7Rb77"
      },
      "source": [
        "## Set up OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w75jomMERZHb",
        "outputId": "214899eb-6d80-4644-c008-24ce3a942df0"
      },
      "source": [
        "# Set up OpenAI API Key\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Try to get API key from Google Colab userdata first (if running in Colab)\n",
        "OPENAI_API_KEY = None\n",
        "try:\n",
        "    import google.colab\n",
        "    from google.colab import userdata\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    if OPENAI_API_KEY:\n",
        "        print(\" OpenAI API Key loaded from Colab userdata!\")\n",
        "except (ImportError, ValueError):\n",
        "    # Not running in Colab or userdata not available, try environment variables\n",
        "    pass\n",
        "\n",
        "# If not found in Colab userdata, try environment variables\n",
        "if not OPENAI_API_KEY:\n",
        "    # Load environment variables from .env file\n",
        "    load_dotenv()\n",
        "    \n",
        "    # Get OpenAI API Key from environment variable\n",
        "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if OPENAI_API_KEY:\n",
        "        print(\" OpenAI API Key loaded from environment variables!\")\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"OPENAI_API_KEY not found. Please set it in one of the following ways:\\n\"\n",
        "            \"  - In Google Colab: userdata.set('OPENAI_API_KEY', 'your_key')\\n\"\n",
        "            \"  - Locally: Create a .env file with OPENAI_API_KEY=your_key\\n\"\n",
        "            \"  - Or set environment variable: export OPENAI_API_KEY=your_key\"\n",
        "        )\n",
        "\n",
        "# Ensure the API key is set in the environment for OpenAI libraries\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "print(\"OpenAI API Key configured successfully!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " OpenAI API Key loaded from environment variables!\n",
            "OpenAI API Key configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCcEpZn5RkLU"
      },
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDa_MkmeRzEE"
      },
      "source": [
        "# Lesson 1: Router Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlO-_ImmR8u1"
      },
      "source": [
        "### Load Data\n",
        "Download the MetaGPT paper:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IWJozRpR3KM",
        "outputId": "3ec00f0e-512a-4ada-d9d5-000e5e3fb743"
      },
      "source": [
        "# Create data directory if it doesn't exist\n",
        "import os\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# Download the MetaGPT paper\n",
        "!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O data/metagpt.pdf"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-12-14 18:00:14--  https://openreview.net/pdf?id=VtmBAGCN7o\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16911937 (16M) [application/pdf]\n",
            "Saving to: data/metagpt.pdf\n",
            "\n",
            "data/metagpt.pdf    100%[===================>]  16.13M  24.2MB/s    in 0.7s    \n",
            "\n",
            "2025-12-14 18:00:16 (24.2 MB/s) - data/metagpt.pdf saved [16911937/16911937]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urqMuc3uSF0l"
      },
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# load documents\n",
        "documents = SimpleDirectoryReader(input_files=[\"data/metagpt.pdf\"]).load_data()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKf_IJp-TMah"
      },
      "source": [
        "## Define LLM and Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-2smc6ITQUh"
      },
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk6roZbpTR_h"
      },
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxpZND2rTUbZ"
      },
      "source": [
        "## Define Summary Index and Vector Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbdFzj_GTWPz"
      },
      "source": [
        "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
        "\n",
        "summary_index = SummaryIndex(nodes)\n",
        "vector_index = VectorStoreIndex(nodes)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:18,147 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBLsNW0YTYUd"
      },
      "source": [
        "## Define Query Engines and Set Metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBy7Qd_gTafp"
      },
      "source": [
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "vector_query_engine = vector_index.as_query_engine()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFLi0Z32TdSa"
      },
      "source": [
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "print(\"Creating summary tool...\")\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"Useful for summarization questions related to MetaGPT\"\n",
        "    ),\n",
        ")\n",
        "print(f\" Summary tool created successfully\")\n",
        "print(f\"  Description: {summary_tool.metadata.description}\")\n",
        "\n",
        "print(\"\\nCreating vector tool...\")\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=vector_query_engine,\n",
        "    description=(\n",
        "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
        "    ),\n",
        ")\n",
        "print(f\" Vector tool created successfully\")\n",
        "print(f\"  Description: {vector_tool.metadata.description}\")\n",
        "print(\"\\n Both tools are ready to use!\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating summary tool...\n",
            " Summary tool created successfully\n",
            "  Description: Useful for summarization questions related to MetaGPT\n",
            "\n",
            "Creating vector tool...\n",
            " Vector tool created successfully\n",
            "  Description: Useful for retrieving specific context from the MetaGPT paper.\n",
            "\n",
            " Both tools are ready to use!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di42S-cSTgFI"
      },
      "source": [
        "## Define Router Query Engine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c_U0uO_TfeK"
      },
      "source": [
        "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        "    verbose=True\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ9zrRopTjiJ",
        "outputId": "9fda8d22-7294-4515-f437-dfc96e542574"
      },
      "source": [
        "response = query_engine.query(\"What is the summary of the document?\")\n",
        "print(str(response))\n",
        "print(len(response.source_nodes))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:18,898 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:18,911 - INFO - Selecting query engine 0: This choice indicates that the document is useful for summarization questions related to MetaGPT..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 0: This choice indicates that the document is useful for summarization questions related to MetaGPT..\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:20,817 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:21,165 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:22,527 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The document introduces MetaGPT, a meta-programming framework that utilizes Standardized Operating Procedures (SOPs) to enhance multi-agent systems based on Large Language Models (LLMs). It incorporates role specialization, workflow management, and efficient communication mechanisms to improve code generation quality. The framework involves agents like Product Managers, Architects, Engineers, and QA Engineers contributing to different stages of software development. Through iterative testing and feedback mechanisms, MetaGPT achieves state-of-the-art performance on various benchmarks. The document also discusses the development of a \"Drawing App\" using MetaGPT, detailing the process from creating a user-friendly GUI to implementing color selection functionality. It covers system architecture, implementation using Python libraries, testing procedures, breakdown of tasks, unit testing, performance evaluation, challenges, ethical concerns, and the impact of MetaGPT on programming accessibility and transparency. Additionally, potential future enhancements like self-improvement mechanisms and multi-agent economies within the MetaGPT framework are discussed.\n",
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qbzrYinTm38",
        "outputId": "88faf2a7-74cf-4fe4-e75f-97b51b0adf5b"
      },
      "source": [
        "response = query_engine.query(\n",
        "    \"How do agents share information with other agents?\"\n",
        ")\n",
        "print(str(response))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:23,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:23,632 - INFO - Selecting query engine 1: This choice is more relevant as it specifically mentions retrieving specific context, which would be necessary to understand how agents share information with other agents..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 1: This choice is more relevant as it specifically mentions retrieving specific context, which would be necessary to understand how agents share information with other agents..\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:23,858 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:25,306 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agents share information with other agents by utilizing a shared message pool where they can publish structured messages. Additionally, agents can subscribe to relevant messages based on their profiles. This approach allows for transparent exchange of information among agents, enabling them to access and retrieve necessary information directly from the shared pool without the need for individual inquiries or waiting for responses.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7P2fB-CTvr8"
      },
      "source": [
        "# Lesson 2: Tool Calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60323azIT4lL"
      },
      "source": [
        "### 1. Define a Simple Tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ8ZXkAQTxLD"
      },
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "\n",
        "def add(x: int, y: int) -> int:\n",
        "    \"\"\"Adds two integers together.\"\"\"\n",
        "    return x + y\n",
        "\n",
        "def mystery(x: int, y: int) -> int:\n",
        "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
        "    return (x + y) * (x + y)\n",
        "\n",
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIcGPDXyT7oM",
        "outputId": "824b01b8-0572-4041-bbd7-3d069bb0ea03"
      },
      "source": [
        "# ============================================================================\n",
        "# EXPLANATION: Using LLM with Function/Tool Calling\n",
        "# ============================================================================\n",
        "# This demonstrates how an LLM can intelligently choose and call functions/tools\n",
        "# based on a natural language query.\n",
        "\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "# Step 1: Initialize the OpenAI LLM\n",
        "# This creates a connection to OpenAI's GPT-3.5-turbo model\n",
        "print(\"Step 1: Initializing OpenAI LLM (gpt-3.5-turbo)...\")\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "print(\" LLM initialized\\n\")\n",
        "\n",
        "# Step 2: Use predict_and_call to let the LLM decide which tool to use\n",
        "# The LLM will:\n",
        "#   - Analyze the query: \"Tell me the output of the mystery function on 2 and 9\"\n",
        "#   - Understand it needs to call a function with arguments 2 and 9\n",
        "#   - Choose the appropriate tool (mystery_tool in this case)\n",
        "#   - Call the function with the correct arguments\n",
        "#   - Return the result\n",
        "\n",
        "print(\"Step 2: LLM analyzing query and selecting appropriate tool...\")\n",
        "print(\"Query: 'Tell me the output of the mystery function on 2 and 9'\")\n",
        "print(\"Available tools: add_tool, mystery_tool\")\n",
        "print(\"\\nLLM reasoning process (verbose=True shows this):\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "response = llm.predict_and_call(\n",
        "    [add_tool, mystery_tool],  # List of available tools the LLM can choose from\n",
        "    \"Tell me the output of the mystery function on 2 and 9\",  # User's query\n",
        "    verbose=True  # Shows the LLM's decision-making process\n",
        ")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(\"\\nStep 3: Final response from LLM:\")\n",
        "print(\"=\" * 60)\n",
        "print(str(response))\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Explanation of what happened:\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"WHAT HAPPENED:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. The LLM received your query asking about 'mystery function'\")\n",
        "print(\"2. It analyzed the available tools and chose 'mystery_tool'\")\n",
        "print(\"3. It extracted the arguments: x=2, y=9\")\n",
        "print(\"4. It called mystery_tool(2, 9) which calculates: (2+9) * (2+9) = 121\")\n",
        "print(\"5. It returned the result: 121\")\n",
        "print(\"=\" * 60)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Initializing OpenAI LLM (gpt-3.5-turbo)...\n",
            " LLM initialized\n",
            "\n",
            "Step 2: LLM analyzing query and selecting appropriate tool...\n",
            "Query: 'Tell me the output of the mystery function on 2 and 9'\n",
            "Available tools: add_tool, mystery_tool\n",
            "\n",
            "LLM reasoning process (verbose=True shows this):\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:26,319 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Calling Function ===\n",
            "Calling function: mystery with args: {\"x\": 2, \"y\": 9}\n",
            "=== Function Output ===\n",
            "121\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step 3: Final response from LLM:\n",
            "============================================================\n",
            "121\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "WHAT HAPPENED:\n",
            "============================================================\n",
            "1. The LLM received your query asking about 'mystery function'\n",
            "2. It analyzed the available tools and chose 'mystery_tool'\n",
            "3. It extracted the arguments: x=2, y=9\n",
            "4. It called mystery_tool(2, 9) which calculates: (2+9) * (2+9) = 121\n",
            "5. It returned the result: 121\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk-Waqk2T-FU"
      },
      "source": [
        "### 2. Define an Auto-Retrieval Tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O_iv2aTT_fz"
      },
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# load documents\n",
        "documents = SimpleDirectoryReader(input_files=[\"data/metagpt.pdf\"]).load_data()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJjN83C8UCIz",
        "outputId": "5ec5f732-ac37-442b-caa0-3311e737779c"
      },
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)\n",
        "print(nodes[0].get_content(metadata_mode=\"all\"))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_label: 1\n",
            "file_name: metagpt.pdf\n",
            "file_path: data/metagpt.pdf\n",
            "file_type: application/pdf\n",
            "file_size: 16911937\n",
            "creation_date: 2025-12-14\n",
            "last_modified_date: 2025-12-14\n",
            "\n",
            "Preprint\n",
            "METAGPT: M ETA PROGRAMMING FOR A\n",
            "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
            "Sirui Hong1, Mingchen Zhuge2, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
            "Ceyao Zhang4, Jinlin Wang1, Zili Wang, Steven Ka Shing Yau5, Zijuan Lin4,\n",
            "Liyang Zhou6, Chenyu Ran1, Lingfeng Xiao1,7, Chenglin Wu1, Jurgen Schmidhuber2,8\n",
            "1DeepWisdom, 2AI Initiative, King Abdullah University of Science and Technology,\n",
            "3Xiamen University, 4The Chinese University of Hong Kong, Shenzhen,\n",
            "5Nanjing University, 6University of Pennsylvania,\n",
            "7University of California, Berkeley, 8The Swiss AI Lab IDSIA/USI/SUPSI\n",
            "ABSTRACT\n",
            "Remarkable progress has been made on automated problem solving through so-\n",
            "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
            "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
            "complex tasks, however, are complicated through logic inconsistencies due to\n",
            "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
            "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
            "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
            "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
            "streamlined workflows, thus allowing agents with human-like domain expertise\n",
            "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
            "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
            "complex tasks into subtasks involving many agents working together. On col-\n",
            "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
            "solutions than previous chat-based multi-agent systems. Our project can be found\n",
            "at https://github.com/geekan/MetaGPT.\n",
            "1 I NTRODUCTION\n",
            "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
            "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
            "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
            "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
            "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
            "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
            "et al., 2023; Qian et al., 2023).\n",
            "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
            "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
            "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
            "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
            "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
            "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
            "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
            "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
            "(PRDs) using a standardized structure, to guide the developmental process.\n",
            "Inspired by such ideas, we design a promising GPT -based Meta-Programming framework called\n",
            "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
            "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
            "These authors contributed equally to this work.\n",
            "Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_O-RStXUDjM"
      },
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "vector_index = VectorStoreIndex(nodes)\n",
        "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:26,960 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQyExE-bUFSk",
        "outputId": "44577393-554b-4d3a-d7f7-84ba651fa9bb"
      },
      "source": [
        "from llama_index.core.vector_stores import MetadataFilters\n",
        "\n",
        "query_engine = vector_index.as_query_engine(\n",
        "    similarity_top_k=2,\n",
        "    filters=MetadataFilters.from_dicts(\n",
        "        [\n",
        "            {\"key\": \"page_label\", \"value\": \"2\"}\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"What are some high-level results of MetaGPT?\",\n",
        ")\n",
        "print(str(response))\n",
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:27,271 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:28,100 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some high-level results of MetaGPT include achieving a new state-of-the-art in code generation benchmarks with 85.9% and 87.7% in Pass@1, outperforming other popular frameworks like AutoGPT, LangChain, AgentVerse, and ChatDev. Additionally, MetaGPT demonstrates robustness and efficiency by achieving a 100% task completion rate in experimental evaluations, highlighting its effectiveness in handling higher levels of software complexity and offering extensive functionality.\n",
            "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'data/metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2025-12-14', 'last_modified_date': '2025-12-14'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGMYtivzUIR-"
      },
      "source": [
        "### Define the Auto-Retrieval Tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a69NkZQDUOYE"
      },
      "source": [
        "from typing import List\n",
        "from llama_index.core.vector_stores import FilterCondition\n",
        "\n",
        "def vector_query(\n",
        "    query: str,\n",
        "    page_numbers: List[str]\n",
        ") -> str:\n",
        "    \"\"\"Perform a vector search over an index.\n",
        "\n",
        "    query (str): the string query to be embedded.\n",
        "    page_numbers (List[str]): Filter by set of pages. Leave BLANK if we want to perform a vector search\n",
        "        over all pages. Otherwise, filter by the set of specified pages.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    metadata_dicts = [\n",
        "        {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
        "    ]\n",
        "\n",
        "    query_engine = vector_index.as_query_engine(\n",
        "        similarity_top_k=2,\n",
        "        filters=MetadataFilters.from_dicts(\n",
        "            metadata_dicts,\n",
        "            condition=FilterCondition.OR\n",
        "        )\n",
        "    )\n",
        "    response = query_engine.query(query)\n",
        "    return response\n",
        "\n",
        "\n",
        "vector_query_tool = FunctionTool.from_defaults(\n",
        "    name=\"vector_tool\",\n",
        "    fn=vector_query\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGWYH4bBUTgl",
        "outputId": "29aac91d-d332-426b-fb25-424143d6d4a2"
      },
      "source": [
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "response = llm.predict_and_call(\n",
        "    [vector_query_tool],\n",
        "    \"What are the high-level results of MetaGPT as described on page 2?\",\n",
        "    verbose=True\n",
        ")\n",
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:28,989 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:29,186 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Calling Function ===\n",
            "Calling function: vector_tool with args: {\"query\": \"high-level results of MetaGPT\", \"page_numbers\": [\"2\"]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:29,929 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Function Output ===\n",
            "MetaGPT achieves a new state-of-the-art (SoTA) in code generation benchmarks with 85.9% and 87.7% in Pass@1. It stands out in handling higher levels of software complexity and offering extensive functionality, demonstrating a 100% task completion rate in experimental evaluations.\n",
            "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'data/metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2025-12-14', 'last_modified_date': '2025-12-14'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdI82mq4UVAf"
      },
      "source": [
        "### Add More Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFANjpM0UbS1"
      },
      "source": [
        "from llama_index.core import SummaryIndex\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "summary_index = SummaryIndex(nodes)\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    name=\"summary_tool\",\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"Useful if you want to get a summary of MetaGPT\"\n",
        "    ),\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN6TUTjIUeP7",
        "outputId": "bcb59ce3-836b-4880-ccc5-354c53cecb34"
      },
      "source": [
        "response = llm.predict_and_call(\n",
        "    [vector_query_tool, summary_tool],\n",
        "    \"What are the MetaGPT comparisons with ChatDev described on page 8?\",\n",
        "    verbose=True\n",
        ")\n",
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:30,434 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:30,607 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Calling Function ===\n",
            "Calling function: vector_tool with args: {\"query\": \"MetaGPT comparisons with ChatDev\", \"page_numbers\": [\"8\"]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:31,466 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Function Output ===\n",
            "MetaGPT outperforms ChatDev on the SoftwareDev dataset in various metrics. For example, MetaGPT achieves a higher score in executability, takes less time for execution, uses more tokens but requires fewer tokens to generate one line of code compared to ChatDev. Additionally, MetaGPT shows better performance in code statistics and human revision cost when compared to ChatDev.\n",
            "{'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'data/metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2025-12-14', 'last_modified_date': '2025-12-14'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLOx8OpkUgDc",
        "outputId": "617f1f07-d5be-4cfd-8db8-8cfcae26e267"
      },
      "source": [
        "response = llm.predict_and_call(\n",
        "    [vector_query_tool, summary_tool],\n",
        "    \"What is a summary of the paper?\",\n",
        "    verbose=True\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:32,490 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:32,584 - INFO - Retrying request to /chat/completions in 0.454054 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\": \"The paper discusses the impact of climate change on biodiversity and ecosystems.\"}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:33,191 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:34,878 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:35,340 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Function Output ===\n",
            "The paper does not discuss the impact of climate change on biodiversity and ecosystems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsuAfoQQUnXF"
      },
      "source": [
        "# Lesson 3: Building an Agent Reasoning Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbG-KyJPUt9C"
      },
      "source": [
        "## Setup Function Calling Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMKPrg-IUqDi"
      },
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrClHpeJUzav"
      },
      "source": [
        "from llama_index.core.agent.workflow import FunctionAgent\n",
        "\n",
        "agent = FunctionAgent(\n",
        "    tools=[vector_tool, summary_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr-IbHktU1P6",
        "outputId": "ffa7c75a-9a06-492d-bf36-0ce625739cb0"
      },
      "source": [
        "# For FunctionAgent - must use asyncio.run() for async execution\n",
        "import asyncio\n",
        "\n",
        "response = asyncio.run(agent.run(\n",
        "    \"Tell me about the agent roles in MetaGPT, and how they communicate.\"\n",
        "))\n",
        "print(str(response))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:35,870 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:36,484 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:36,502 - INFO - Retrying request to /chat/completions in 0.477865 seconds\n",
            "2025-12-14 18:00:36,985 - INFO - Retrying request to /chat/completions in 0.778235 seconds\n",
            "2025-12-14 18:00:38,943 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:39,335 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In MetaGPT, the agent roles are defined based on specific tasks and expertise, such as Product Manager, Architect, Project Manager, Engineer, and QA Engineer. These roles are tailored to handle different aspects of the software development process. Communication among these agents is facilitated through a shared message pool where structured messages are published and accessed. Agents can subscribe to relevant messages based on their profiles, allowing for efficient exchange of information. This approach ensures that agents can obtain necessary information from other roles and the environment, enhancing collaboration and productivity within the multi-agent system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJpxzzjfU37G",
        "outputId": "7ba8eaf8-60e1-4ac9-9661-1e61c78d83eb"
      },
      "source": [
        "response = asyncio.run(agent.run(\n",
        "    \"Tell me about the evaluation datasets used.\"\n",
        "))\n",
        "print(str(response))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:40,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:40,669 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:41,301 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:42,227 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The evaluation datasets used are HumanEval, MBPP, and SoftwareDev.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOZowgzOU6Ie",
        "outputId": "3b5cea53-0019-4347-da55-653478abdccf"
      },
      "source": [
        "response = asyncio.run(agent.run(\"Tell me the results over one of the above datasets.\"))\n",
        "\n",
        "print(str(response))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:42,825 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:43,558 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:44,019 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:44,908 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The results over dataset A show that MetaGPT achieved an average score of 3.9, surpassing ChatDev's score of 2.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBRDERx3WiPM"
      },
      "source": [
        "# Lesson 4: Building a Multi-Document Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC-ZUdZqWlkY"
      },
      "source": [
        "## 1. Setup an Agent Over 3 Papers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p_5UBCMWlAt"
      },
      "source": [
        "urls = [\n",
        "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
        "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
        "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
        "]\n",
        "\n",
        "papers = [\n",
        "    \"metagpt.pdf\",\n",
        "    \"longlora.pdf\",\n",
        "    \"selfrag.pdf\",\n",
        "]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nCY_iZXWq3D",
        "outputId": "5cc631d1-1543-413f-fcc2-e7de21fde836"
      },
      "source": [
        "# Download papers\n",
        "for url, paper in zip(urls, papers):\n",
        "    !wget \"{url}\" -O \"data/{paper}\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-12-14 18:00:45--  https://openreview.net/pdf?id=VtmBAGCN7o\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16911937 (16M) [application/pdf]\n",
            "Saving to: data/metagpt.pdf\n",
            "\n",
            "data/metagpt.pdf    100%[===================>]  16.13M  30.7MB/s    in 0.5s    \n",
            "\n",
            "2025-12-14 18:00:46 (30.7 MB/s) - data/metagpt.pdf saved [16911937/16911937]\n",
            "\n",
            "--2025-12-14 18:00:46--  https://openreview.net/pdf?id=6PmJoRfdaK\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1168720 (1.1M) [application/pdf]\n",
            "Saving to: data/longlora.pdf\n",
            "\n",
            "data/longlora.pdf   100%[===================>]   1.11M  5.69MB/s    in 0.2s    \n",
            "\n",
            "2025-12-14 18:00:46 (5.69 MB/s) - data/longlora.pdf saved [1168720/1168720]\n",
            "\n",
            "--2025-12-14 18:00:47--  https://openreview.net/pdf?id=hSyW5go0v8\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1244749 (1.2M) [application/pdf]\n",
            "Saving to: data/selfrag.pdf\n",
            "\n",
            "data/selfrag.pdf    100%[===================>]   1.19M  5.87MB/s    in 0.2s    \n",
            "\n",
            "2025-12-14 18:00:47 (5.87 MB/s) - data/selfrag.pdf saved [1244749/1244749]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_PZDk3lWtET"
      },
      "source": [
        "# Helper function to create tools for each paper\n",
        "# Works in both Google Colab and local environments\n",
        "from pathlib import Path\n",
        "from llama_index.core import SimpleDirectoryReader, SummaryIndex, VectorStoreIndex\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "def get_doc_tools(file_path: str, name: str):\n",
        "    \"\"\"\n",
        "    Get vector and summary query engine tools from a document.\n",
        "    \n",
        "    This function works in both Google Colab and local environments.\n",
        "    Make sure Settings.llm and Settings.embed_model are configured before calling this function.\n",
        "    \n",
        "    Args:\n",
        "        file_path: Path to the document file (relative or absolute path)\n",
        "        name: Name identifier for the document (used in tool descriptions)\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (vector_tool, summary_tool) - QueryEngineTool instances\n",
        "    \"\"\"\n",
        "\n",
        "    # Load documents\n",
        "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
        "    splitter = SentenceSplitter(chunk_size=1024)\n",
        "    nodes = splitter.get_nodes_from_documents(documents)\n",
        "\n",
        "    # Create indices\n",
        "    vector_index = VectorStoreIndex(nodes)\n",
        "    summary_index = SummaryIndex(nodes)\n",
        "\n",
        "    # Create query engines\n",
        "    vector_query_engine = vector_index.as_query_engine()\n",
        "    summary_query_engine = summary_index.as_query_engine(\n",
        "        response_mode=\"tree_summarize\",\n",
        "        use_async=True,\n",
        "    )\n",
        "\n",
        "    # Create tools with improved descriptions that include paper name variations\n",
        "    # Map common filename patterns to proper paper names\n",
        "    paper_name_map = {\n",
        "        \"selfrag\": \"Self-RAG\",\n",
        "        \"longlora\": \"LongLoRA\",\n",
        "        \"metagpt\": \"MetaGPT\",\n",
        "        \"loftq\": \"LoftQ\",\n",
        "    }\n",
        "    \n",
        "    # Get proper paper name or use the provided name\n",
        "    paper_name = paper_name_map.get(name.lower(), name.replace(\"_\", \"-\").title())\n",
        "    \n",
        "    # Create tools with explicit names and improved descriptions\n",
        "    vector_tool = QueryEngineTool.from_defaults(\n",
        "        query_engine=vector_query_engine,\n",
        "        name=f\"{paper_name}_vector_tool\",\n",
        "        description=(\n",
        "            f\"Use this tool to retrieve specific context, details, facts, or information from the {paper_name} paper. \"\n",
        "            f\"Use when asked about {paper_name}, {name}, or {name.replace('_', '-')}. \"\n",
        "            f\"This tool searches the {paper_name} paper for specific information.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    summary_tool = QueryEngineTool.from_defaults(\n",
        "        query_engine=summary_query_engine,\n",
        "        name=f\"{paper_name}_summary_tool\",\n",
        "        description=(\n",
        "            f\"Use this tool to get summaries, overviews, or high-level information about the {paper_name} paper. \"\n",
        "            f\"Use when asked for a summary of {paper_name}, {name}, or {name.replace('_', '-')}. \"\n",
        "            f\"This tool provides comprehensive summaries of the {paper_name} paper.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return vector_tool, summary_tool"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHKWRYVGWunE",
        "outputId": "9f0019b4-e82d-43b5-8152-18de05818cc5"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "paper_to_tools_dict = {}\n",
        "for paper in papers:\n",
        "    print(f\"Getting tools for paper: {paper}\")\n",
        "    \n",
        "    # Check if file exists in data directory before processing\n",
        "    file_path = f\"data/{paper}\"\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"    Warning: File '{file_path}' does not exist. Skipping...\")\n",
        "        print(f\"   Tip: Make sure you've downloaded all papers first.\")\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        vector_tool, summary_tool = get_doc_tools(file_path, Path(paper).stem)\n",
        "        paper_to_tools_dict[paper] = [vector_tool, summary_tool]\n",
        "        print(f\"   Successfully created tools for {paper}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error processing {paper}: {e}\")\n",
        "        print(f\"  Skipping this paper...\\n\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\n Successfully processed {len(paper_to_tools_dict)} papers\")\n",
        "print(f\"Papers with tools: {list(paper_to_tools_dict.keys())}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting tools for paper: metagpt.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:48,472 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for metagpt.pdf\n",
            "\n",
            "Getting tools for paper: longlora.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:49,582 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for longlora.pdf\n",
            "\n",
            "Getting tools for paper: selfrag.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:50,834 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for selfrag.pdf\n",
            "\n",
            "\n",
            " Successfully processed 3 papers\n",
            "Papers with tools: ['metagpt.pdf', 'longlora.pdf', 'selfrag.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZRNhKIhWvcr"
      },
      "source": [
        "initial_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1CKgcR_WyBr",
        "outputId": "98d6d1e2-72fb-4b0c-e84a-0e1dc65c82e6"
      },
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "print(f\"Number of tools: {len(initial_tools)}\")\n",
        "\n",
        "# Debug: Print tool information\n",
        "if len(initial_tools) > 0:\n",
        "    print(f\"\\n Tools available:\")\n",
        "    for i, tool in enumerate(initial_tools[:6]):  # Show first 6 tools\n",
        "        # ToolMetadata is an object, not a dict - access attributes directly\n",
        "        if hasattr(tool, 'metadata') and tool.metadata:\n",
        "            tool_name = getattr(tool.metadata, 'name', 'Unknown')\n",
        "            tool_desc = getattr(tool.metadata, 'description', 'No description')\n",
        "        else:\n",
        "            tool_name = 'Unknown'\n",
        "            tool_desc = 'No description'\n",
        "        print(f\"  Tool {i+1}: {tool_name}\")\n",
        "        print(f\"    Description: {tool_desc[:80]}...\")\n",
        "else:\n",
        "    print(\"\\n WARNING: No tools available! Make sure papers were processed successfully.\")\n",
        "    print(f\"   paper_to_tools_dict has {len(paper_to_tools_dict)} papers\")\n",
        "    print(f\"   papers list: {papers}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tools: 6\n",
            "\n",
            " Tools available:\n",
            "  Tool 1: MetaGPT_vector_tool\n",
            "    Description: Use this tool to retrieve specific context, details, facts, or information from ...\n",
            "  Tool 2: MetaGPT_summary_tool\n",
            "    Description: Use this tool to get summaries, overviews, or high-level information about the M...\n",
            "  Tool 3: LongLoRA_vector_tool\n",
            "    Description: Use this tool to retrieve specific context, details, facts, or information from ...\n",
            "  Tool 4: LongLoRA_summary_tool\n",
            "    Description: Use this tool to get summaries, overviews, or high-level information about the L...\n",
            "  Tool 5: Self-RAG_vector_tool\n",
            "    Description: Use this tool to retrieve specific context, details, facts, or information from ...\n",
            "  Tool 6: Self-RAG_summary_tool\n",
            "    Description: Use this tool to get summaries, overviews, or high-level information about the S...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrotN19WWzv8"
      },
      "source": [
        "# LlamaIndex >= 0.14.6\n",
        "from llama_index.core.agent.workflow import FunctionAgent\n",
        "\n",
        "if len(initial_tools) == 0:\n",
        "    raise ValueError(\n",
        "        \"ERROR: No tools available! Make sure papers were processed successfully.\\n\"\n",
        "        f\"paper_to_tools_dict has {len(paper_to_tools_dict)} entries.\\n\"\n",
        "        \"Run the paper processing cell above and check for errors.\"\n",
        "    )\n",
        "\n",
        "# Verify tools are properly configured and callable\n",
        "print(f\" Creating agent with {len(initial_tools)} tools\")\n",
        "tool_names = []\n",
        "tool_descriptions = []\n",
        "\n",
        "for tool in initial_tools:\n",
        "    # ToolMetadata is an object, access attributes directly\n",
        "    if hasattr(tool, 'metadata') and tool.metadata:\n",
        "        tool_name = getattr(tool.metadata, 'name', 'Unknown')\n",
        "        tool_desc = getattr(tool.metadata, 'description', 'No description')\n",
        "    else:\n",
        "        tool_name = 'Unknown'\n",
        "        tool_desc = 'No description'\n",
        "    \n",
        "    tool_names.append(tool_name)\n",
        "    tool_descriptions.append(f\"{tool_name}: {tool_desc[:80]}...\")\n",
        "    \n",
        "    # Verify tool has required methods for FunctionAgent\n",
        "    has_call = hasattr(tool, 'call') or hasattr(tool, 'acall') or callable(tool)\n",
        "    if not has_call:\n",
        "        print(f\"  Warning: Tool {tool_name} may not be callable - missing call methods\")\n",
        "\n",
        "print(f\"\\n Available tools:\")\n",
        "for desc in tool_descriptions:\n",
        "    print(f\"   {desc}\")\n",
        "\n",
        "# Build a comprehensive system prompt that lists all available tools with descriptions\n",
        "tool_list_with_desc = \"\\n\".join([f\"  - {name}: {desc[:100]}...\" for name, desc in zip(tool_names, [getattr(t.metadata, 'description', '') if hasattr(t, 'metadata') and t.metadata else '' for t in initial_tools])])\n",
        "\n",
        "# Create agent with explicit instructions and tool list\n",
        "# CRITICAL: FunctionAgent needs tools to be properly formatted QueryEngineTool instances\n",
        "agent = FunctionAgent(\n",
        "    tools=initial_tools,  # These should be QueryEngineTool instances from get_doc_tools\n",
        "    llm=llm,\n",
        "    verbose=True,  # Shows detailed tool selection and calling - IMPORTANT for debugging\n",
        "    system_prompt=(\n",
        "        \"You are a research assistant with access to tools for querying academic papers. \"\n",
        "        \"CRITICAL: You MUST use the available tools to answer ALL questions. \"\n",
        "        \"Never say you cannot retrieve information - always try the tools first.\\n\\n\"\n",
        "        f\"AVAILABLE TOOLS (you MUST use these):\\n{tool_list_with_desc}\\n\\n\"\n",
        "        \"TOOL SELECTION RULES:\\n\"\n",
        "        \"1. When asked about 'Self-RAG' or 'selfrag', you MUST call a tool with 'Self-RAG' in the name.\\n\"\n",
        "        \"2. When asked about 'LongLoRA' or 'longlora', you MUST call a tool with 'LongLoRA' in the name.\\n\"\n",
        "        \"3. When asked about 'MetaGPT' or 'metagpt', you MUST call a tool with 'MetaGPT' in the name.\\n\"\n",
        "        \"4. For summary requests (e.g., 'give me a summary', 'summarize'), use tools ending with '_summary_tool'.\\n\"\n",
        "        \"5. For specific details, facts, or questions, use tools ending with '_vector_tool'.\\n\\n\"\n",
        "        \"EXAMPLES OF CORRECT TOOL USAGE:\\n\"\n",
        "        \"- Query: 'Give me a summary of Self-RAG'  MUST call 'Self-RAG_summary_tool'\\n\"\n",
        "        \"- Query: 'Tell me about LongLoRA'  MUST call 'LongLoRA_summary_tool' or 'LongLoRA_vector_tool'\\n\"\n",
        "        \"- Query: 'What datasets does MetaGPT use?'  MUST call 'MetaGPT_vector_tool'\\n\"\n",
        "        \"- Query: 'Give me a summary of both Self-RAG and LongLoRA'  MUST call BOTH 'Self-RAG_summary_tool' AND 'LongLoRA_summary_tool'\\n\\n\"\n",
        "        \"MANDATORY BEHAVIOR:\\n\"\n",
        "        \"- ALWAYS call at least one tool before responding\\n\"\n",
        "        \"- If a tool call fails, try another tool for the same paper\\n\"\n",
        "        \"- NEVER respond without calling a tool first\\n\"\n",
        "        \"- NEVER say 'I cannot retrieve information' or 'I don't have access' - you have tools, use them!\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(\"\\n Agent created successfully\")\n",
        "print(\" Tip: With verbose=True, you'll see detailed logs of tool selection and calls\")\n",
        ""
      ],
      "execution_count": 36,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Creating agent with 6 tools\n",
            "   Available tools: MetaGPT_vector_tool, MetaGPT_summary_tool, LongLoRA_vector_tool, LongLoRA_summary_tool, Self-RAG_vector_tool, Self-RAG_summary_tool\n",
            " Agent created successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Debug: Print all available tools with their names and descriptions\n",
        "print(\"=\"*60)\n",
        "print(\"AVAILABLE TOOLS FOR AGENT:\")\n",
        "print(\"=\"*60)\n",
        "if len(initial_tools) == 0:\n",
        "    print(\" ERROR: No tools available!\")\n",
        "    print(f\"   paper_to_tools_dict has {len(paper_to_tools_dict)} entries\")\n",
        "    print(f\"   papers list: {papers}\")\n",
        "    print(\"\\n Make sure you've:\")\n",
        "    print(\"   1. Downloaded all papers (run the download cell)\")\n",
        "    print(\"   2. Successfully processed papers (check for errors above)\")\n",
        "else:\n",
        "    for i, tool in enumerate(initial_tools, 1):\n",
        "        # ToolMetadata is an object, access attributes directly\n",
        "        if hasattr(tool, 'metadata') and tool.metadata:\n",
        "            tool_name = getattr(tool.metadata, 'name', 'Unknown')\n",
        "            tool_desc = getattr(tool.metadata, 'description', 'No description')\n",
        "        else:\n",
        "            tool_name = 'Unknown'\n",
        "            tool_desc = 'No description'\n",
        "        print(f\"\\nTool {i}: {tool_name}\")\n",
        "        print(f\"  Description: {tool_desc[:100]}...\")\n",
        "    print(f\"\\n Total: {len(initial_tools)} tools available\")\n",
        "    print(\"=\"*60)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "AVAILABLE TOOLS FOR AGENT:\n",
            "============================================================\n",
            "\n",
            "Tool 1: MetaGPT_vector_tool\n",
            "  Description: Use this tool to retrieve specific context, details, facts, or information from the MetaGPT paper. U...\n",
            "\n",
            "Tool 2: MetaGPT_summary_tool\n",
            "  Description: Use this tool to get summaries, overviews, or high-level information about the MetaGPT paper. Use wh...\n",
            "\n",
            "Tool 3: LongLoRA_vector_tool\n",
            "  Description: Use this tool to retrieve specific context, details, facts, or information from the LongLoRA paper. ...\n",
            "\n",
            "Tool 4: LongLoRA_summary_tool\n",
            "  Description: Use this tool to get summaries, overviews, or high-level information about the LongLoRA paper. Use w...\n",
            "\n",
            "Tool 5: Self-RAG_vector_tool\n",
            "  Description: Use this tool to retrieve specific context, details, facts, or information from the Self-RAG paper. ...\n",
            "\n",
            "Tool 6: Self-RAG_summary_tool\n",
            "  Description: Use this tool to get summaries, overviews, or high-level information about the Self-RAG paper. Use w...\n",
            "\n",
            " Total: 6 tools available\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test if tools are actually callable before using agent\n",
        "print(\" Testing tool callability:\\n\")\n",
        "if len(initial_tools) > 0:\n",
        "    # Test calling a summary tool directly\n",
        "    test_tool = None\n",
        "    for tool in initial_tools:\n",
        "        if 'summary' in str(tool.metadata.name).lower() if hasattr(tool, 'metadata') else '':\n",
        "            test_tool = tool\n",
        "            break\n",
        "    \n",
        "    if test_tool:\n",
        "        print(f\"Testing tool: {getattr(test_tool.metadata, 'name', 'Unknown')}\")\n",
        "        try:\n",
        "            # Try to call the tool directly\n",
        "            test_result = test_tool.call(\"What is this paper about?\")\n",
        "            print(f\" Tool is callable! Result preview: {str(test_result)[:100]}...\")\n",
        "        except Exception as e:\n",
        "            print(f\" Tool call failed: {e}\")\n",
        "            print(\"   This might be why the agent can't use the tools\")\n",
        "    else:\n",
        "        print(\"  Could not find a summary tool to test\")\n",
        "else:\n",
        "    print(\" No tools to test\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Testing tool callability:\n",
            "\n",
            "Testing tool: MetaGPT_summary_tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:52,253 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:52,699 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:54,168 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Tool is callable! Result preview: The paper discusses a meta-programming framework called MetaGPT that utilizes Standardized Operating...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbx2Xa5YW6At",
        "outputId": "842b5dbf-8766-49b2-aedf-4c2d9121d0dd"
      },
      "source": [
        "import asyncio\n",
        "\n",
        "response = asyncio.run(agent.run(\n",
        "    user_msg=(\n",
        "        \"Tell me about the evaluation dataset used in LongLoRA, \"\n",
        "        \"and then tell me about the evaluation results\"\n",
        "    )\n",
        "))\n",
        "print(str(response))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:55,039 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:55,297 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:55,313 - INFO - Retrying request to /chat/completions in 0.453204 seconds\n",
            "2025-12-14 18:00:55,314 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:55,323 - INFO - Retrying request to /chat/completions in 0.389740 seconds\n",
            "2025-12-14 18:00:56,175 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:56,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:57,348 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The evaluation dataset used in LongLoRA is the PG19 test split. The evaluation results on this dataset show that as the evaluation context length increases, the models achieve better perplexity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the Agent\n",
        "\n",
        "The agent is configured with all available tools. It should automatically select and use the appropriate tool based on your query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7YAEWvXW8X8",
        "outputId": "503250ca-3c48-4e77-db34-eacf144f378c"
      },
      "source": [
        "import asyncio\n",
        "\n",
        "response = asyncio.run(\n",
        "    agent.run(\n",
        "        user_msg=\"Give me a summary of both Self-RAG and LongLoRA\"\n",
        "    )\n",
        ")\n",
        "print(str(response))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:00:58,148 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:59,802 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:00:59,810 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:00,070 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:00,269 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:00,846 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:01,986 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:02,409 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Self-RAG framework enhances large language models by integrating retrieval on demand and self-reflection through reflection tokens. It allows for customizing model behaviors at test time and surpasses other models in various tasks, enhancing model performance, factuality, and citation accuracy. The system evaluates text quality based on evidence and instructions to improve precision and quality by integrating fine-grained evaluations and feedback mechanisms.\n",
            "\n",
            "On the other hand, the LongLoRA method extends the context length of large language models efficiently while preserving accuracy. It introduces S2-Attn during training to approximate self-attention patterns and uses trainable normalization and embedding layers for fine-tuning. This enables significant extensions in context length for models like Llama2 7B and 70B models. LongLoRA demonstrates promising results in long-sequence language modeling and retrieval-based evaluations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jGd-H9zW95t"
      },
      "source": [
        "## 2. Setup an Agent Over 11 Papers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test the agent with a simple query to verify it calls tools\n",
        "print(\" Testing agent with a simple query:\\n\")\n",
        "import asyncio\n",
        "\n",
        "try:\n",
        "    # Test with a simple, direct query\n",
        "    test_response = asyncio.run(agent.run(\n",
        "        user_msg=\"Give me a summary of Self-RAG\"\n",
        "    ))\n",
        "    print(f\"\\n Agent response preview: {str(test_response)[:300]}...\")\n",
        "    print(\"\\n If you see tool calls in the verbose output above, the agent is working!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n Agent test failed: {type(e).__name__}: {e}\")\n",
        "    print(\"   Check the verbose output above to see what went wrong\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZTLBxFUXBX5"
      },
      "source": [
        "urls = [\n",
        "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
        "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
        "    \"https://openreview.net/pdf?id=LzPWWPAdY4\",\n",
        "    \"https://openreview.net/pdf?id=VTF8yNQM66\",\n",
        "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
        "    \"https://openreview.net/pdf?id=9WD9KwssyT\",\n",
        "    \"https://openreview.net/pdf?id=yV6fD7LYkF\",\n",
        "    \"https://openreview.net/pdf?id=hnrB5YHoYu\",\n",
        "    \"https://openreview.net/pdf?id=WbWtOYIzIK\",\n",
        "    \"https://openreview.net/pdf?id=c5pwL0Soay\",\n",
        "    \"https://openreview.net/pdf?id=TpD2aG1h0D\"\n",
        "]\n",
        "\n",
        "papers = [\n",
        "    \"metagpt.pdf\",\n",
        "    \"longlora.pdf\",\n",
        "    \"loftq.pdf\",\n",
        "    \"swebench.pdf\",\n",
        "    \"selfrag.pdf\",\n",
        "    \"zipformer.pdf\",\n",
        "    \"values.pdf\",\n",
        "    \"finetune_fair_diffusion.pdf\",\n",
        "    \"knowledge_card.pdf\",\n",
        "    \"metra.pdf\",\n",
        "    \"vr_mcl.pdf\"\n",
        "]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCo2FY1jXESb",
        "outputId": "18c92fa6-bd24-4dd6-81d9-a7b97dff31ae"
      },
      "source": [
        "# Download all papers\n",
        "for url, paper in zip(urls, papers):\n",
        "    !wget \"{url}\" -O \"data/{paper}\""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-12-14 18:01:03--  https://openreview.net/pdf?id=VtmBAGCN7o\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16911937 (16M) [application/pdf]\n",
            "Saving to: data/metagpt.pdf\n",
            "\n",
            "data/metagpt.pdf    100%[===================>]  16.13M  28.5MB/s    in 0.6s    \n",
            "\n",
            "2025-12-14 18:01:04 (28.5 MB/s) - data/metagpt.pdf saved [16911937/16911937]\n",
            "\n",
            "--2025-12-14 18:01:04--  https://openreview.net/pdf?id=6PmJoRfdaK\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1168720 (1.1M) [application/pdf]\n",
            "Saving to: data/longlora.pdf\n",
            "\n",
            "data/longlora.pdf   100%[===================>]   1.11M  5.49MB/s    in 0.2s    \n",
            "\n",
            "2025-12-14 18:01:04 (5.49 MB/s) - data/longlora.pdf saved [1168720/1168720]\n",
            "\n",
            "--2025-12-14 18:01:05--  https://openreview.net/pdf?id=LzPWWPAdY4\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 366134 (358K) [application/pdf]\n",
            "Saving to: data/loftq.pdf\n",
            "\n",
            "data/loftq.pdf      100%[===================>] 357.55K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-14 18:01:05 (2.94 MB/s) - data/loftq.pdf saved [366134/366134]\n",
            "\n",
            "--2025-12-14 18:01:05--  https://openreview.net/pdf?id=VTF8yNQM66\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2680380 (2.6M) [application/pdf]\n",
            "Saving to: data/swebench.pdf\n",
            "\n",
            "data/swebench.pdf   100%[===================>]   2.56M  10.3MB/s    in 0.2s    \n",
            "\n",
            "2025-12-14 18:01:06 (10.3 MB/s) - data/swebench.pdf saved [2680380/2680380]\n",
            "\n",
            "--2025-12-14 18:01:06--  https://openreview.net/pdf?id=hSyW5go0v8\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1244749 (1.2M) [application/pdf]\n",
            "Saving to: data/selfrag.pdf\n",
            "\n",
            "data/selfrag.pdf    100%[===================>]   1.19M  5.69MB/s    in 0.2s    \n",
            "\n",
            "2025-12-14 18:01:07 (5.69 MB/s) - data/selfrag.pdf saved [1244749/1244749]\n",
            "\n",
            "--2025-12-14 18:01:07--  https://openreview.net/pdf?id=9WD9KwssyT\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 511626 (500K) [application/pdf]\n",
            "Saving to: data/zipformer.pdf\n",
            "\n",
            "data/zipformer.pdf  100%[===================>] 499.63K  2.99MB/s    in 0.2s    \n",
            "\n",
            "2025-12-14 18:01:07 (2.99 MB/s) - data/zipformer.pdf saved [511626/511626]\n",
            "\n",
            "--2025-12-14 18:01:08--  https://openreview.net/pdf?id=yV6fD7LYkF\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4171982 (4.0M) [application/pdf]\n",
            "Saving to: data/values.pdf\n",
            "\n",
            "data/values.pdf     100%[===================>]   3.98M  13.4MB/s    in 0.3s    \n",
            "\n",
            "2025-12-14 18:01:08 (13.4 MB/s) - data/values.pdf saved [4171982/4171982]\n",
            "\n",
            "--2025-12-14 18:01:08--  https://openreview.net/pdf?id=hnrB5YHoYu\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34710410 (33M) [application/pdf]\n",
            "Saving to: data/finetune_fair_diffusion.pdf\n",
            "\n",
            "data/finetune_fair_ 100%[===================>]  33.10M  31.8MB/s    in 1.0s    \n",
            "\n",
            "2025-12-14 18:01:10 (31.8 MB/s) - data/finetune_fair_diffusion.pdf saved [34710410/34710410]\n",
            "\n",
            "--2025-12-14 18:01:10--  https://openreview.net/pdf?id=WbWtOYIzIK\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 877083 (857K) [application/pdf]\n",
            "Saving to: data/knowledge_card.pdf\n",
            "\n",
            "data/knowledge_card 100%[===================>] 856.53K  5.42MB/s    in 0.2s    \n",
            "\n",
            "2025-12-14 18:01:10 (5.42 MB/s) - data/knowledge_card.pdf saved [877083/877083]\n",
            "\n",
            "--2025-12-14 18:01:10--  https://openreview.net/pdf?id=c5pwL0Soay\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4775879 (4.6M) [application/pdf]\n",
            "Saving to: data/metra.pdf\n",
            "\n",
            "data/metra.pdf      100%[===================>]   4.55M  15.3MB/s    in 0.3s    \n",
            "\n",
            "2025-12-14 18:01:11 (15.3 MB/s) - data/metra.pdf saved [4775879/4775879]\n",
            "\n",
            "--2025-12-14 18:01:11--  https://openreview.net/pdf?id=TpD2aG1h0D\n",
            "Resolving openreview.net (openreview.net)... 34.57.44.88\n",
            "Connecting to openreview.net (openreview.net)|34.57.44.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1973959 (1.9M) [application/pdf]\n",
            "Saving to: data/vr_mcl.pdf\n",
            "\n",
            "data/vr_mcl.pdf     100%[===================>]   1.88M  7.72MB/s    in 0.2s    \n",
            "\n",
            "2025-12-14 18:01:12 (7.72 MB/s) - data/vr_mcl.pdf saved [1973959/1973959]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2YQ6MCLXGjc",
        "outputId": "4ff70cf5-19ee-42fb-8b6f-f45e0b495097"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "paper_to_tools_dict = {}\n",
        "\n",
        "for paper in papers:\n",
        "    print(f\"Getting tools for paper: {paper}\")\n",
        "    \n",
        "    # Check if file exists in data directory before processing\n",
        "    file_path = f\"data/{paper}\"\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"    Warning: File '{file_path}' does not exist. Skipping...\")\n",
        "        print(f\"   Tip: Make sure you've downloaded all papers first.\")\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        vector_tool, summary_tool = get_doc_tools(file_path, Path(paper).stem)\n",
        "        paper_to_tools_dict[paper] = [vector_tool, summary_tool]\n",
        "        print(f\"   Successfully created tools for {paper}\")\n",
        "\n",
        "    except UnicodeEncodeError as e:\n",
        "        print(f\" Unicode error while processing {paper}: {e}\")\n",
        "        try:\n",
        "            # Attempt to re-read text safely and re-generate tools\n",
        "            text_bytes = Path(file_path).read_bytes()\n",
        "            safe_text = text_bytes.decode(\"utf-8\", errors=\"replace\")\n",
        "\n",
        "            # Optionally, save the cleaned text for inspection\n",
        "            clean_path = Path(file_path).with_name(Path(file_path).stem + \"_clean.txt\")\n",
        "            clean_path.write_text(safe_text, encoding=\"utf-8\")\n",
        "            print(f\"Saved cleaned version: {clean_path}\")\n",
        "\n",
        "            # Retry tool creation if your get_doc_tools can accept a string path\n",
        "            vector_tool, summary_tool = get_doc_tools(str(clean_path), Path(paper).stem)\n",
        "            paper_to_tools_dict[paper] = [vector_tool, summary_tool]\n",
        "            print(f\" Retried successfully for {paper}\")\n",
        "\n",
        "        except Exception as inner_e:\n",
        "            print(f\" Still failed on {paper}: {inner_e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Unexpected error for {paper}: {e}\")\n",
        "\n",
        "print(f\"\\n Successfully processed {len(paper_to_tools_dict)} papers\")\n",
        "print(f\"Papers with tools: {list(paper_to_tools_dict.keys())}\")\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting tools for paper: metagpt.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:13,447 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for metagpt.pdf\n",
            "Getting tools for paper: longlora.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:14,698 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for longlora.pdf\n",
            "Getting tools for paper: loftq.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:15,523 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for loftq.pdf\n",
            "Getting tools for paper: swebench.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:17,704 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for swebench.pdf\n",
            "Getting tools for paper: selfrag.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:19,819 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for selfrag.pdf\n",
            "Getting tools for paper: zipformer.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:20,513 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for zipformer.pdf\n",
            "Getting tools for paper: values.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:21,890 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for values.pdf\n",
            "Getting tools for paper: finetune_fair_diffusion.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:25,971 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for finetune_fair_diffusion.pdf\n",
            "Getting tools for paper: knowledge_card.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:27,272 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for knowledge_card.pdf\n",
            "Getting tools for paper: metra.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:28,604 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Successfully created tools for metra.pdf\n",
            "Getting tools for paper: vr_mcl.pdf\n",
            " Unicode error while processing vr_mcl.pdf: 'utf-8' codec can't encode character '\\ud835' in position 94329: surrogates not allowed\n",
            "Saved cleaned version: data/vr_mcl_clean.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:31,474 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:32,784 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:33,928 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:34,850 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:36,268 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:37,162 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:37,922 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:39,869 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:40,689 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:41,915 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:42,589 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:43,628 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:44,931 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:45,810 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:46,926 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:48,156 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:48,798 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:49,843 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:51,026 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:52,047 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Retried successfully for vr_mcl.pdf\n",
            "\n",
            " Successfully processed 11 papers\n",
            "Papers with tools: ['metagpt.pdf', 'longlora.pdf', 'loftq.pdf', 'swebench.pdf', 'selfrag.pdf', 'zipformer.pdf', 'values.pdf', 'finetune_fair_diffusion.pdf', 'knowledge_card.pdf', 'metra.pdf', 'vr_mcl.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ4I4TvuXJ5V"
      },
      "source": [
        "## Extend the Agent with Tool Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ydbcE-RXMi7"
      },
      "source": [
        "all_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zTX2YhlXOlz"
      },
      "source": [
        "# Define an \"object\" index and retriever over these tools\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.objects import ObjectIndex\n",
        "\n",
        "obj_index = ObjectIndex.from_objects(\n",
        "    all_tools,\n",
        "    index_cls=VectorStoreIndex,\n",
        ")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:54,007 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD46kQ4aXRAm"
      },
      "source": [
        "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EJybydrXSzx",
        "outputId": "8f4b6950-a3cd-465b-bc72-770fd4b3ea55"
      },
      "source": [
        "tools = obj_retriever.retrieve(\n",
        "    \"Tell me about the eval dataset used in MetaGPT and SWE-Bench\"\n",
        ")\n",
        "tools[2].metadata"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:54,211 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ToolMetadata(description='Use this tool to get summaries, overviews, or high-level information about the Swebench paper. Use when asked for a summary of Swebench, swebench, or swebench. This tool provides comprehensive summaries of the Swebench paper.', name='Swebench_summary_tool', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjX1Z260XVCu"
      },
      "source": [
        "from llama_index.core.agent.workflow import FunctionAgent\n",
        "from llama_index.core.tools import RetrieverTool  #  wrap retrievers as tools\n",
        "\n",
        "retriever_tool = RetrieverTool.from_defaults(\n",
        "    retriever=obj_retriever,\n",
        "    name=\"paper_retriever\",\n",
        "    description=\"Retrieve relevant chunks from the loaded papers.\"\n",
        ")\n",
        "\n",
        "agent = FunctionAgent(\n",
        "    tools=[retriever_tool],\n",
        "    llm=llm,\n",
        "    system_prompt=(\n",
        "        \"You are an agent designed to answer queries over a set of given papers. \"\n",
        "        \"Always use the provided tools to answer a question. Do not rely on prior knowledge.\"\n",
        "    ),\n",
        "    verbose=True,\n",
        ")\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pwRmYl81ZLD",
        "outputId": "f1016d2a-5c89-499a-e56a-05ae95ef6eaf"
      },
      "source": [
        "import asyncio\n",
        "\n",
        "response = asyncio.run(\n",
        "    agent.run(\n",
        "        user_msg=\"Give me a summary of both Self-RAG and LongLoRA\"\n",
        "    )\n",
        ")\n",
        "print(str(response))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:55,589 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:55,767 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:55,772 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:56,147 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:57,047 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:57,079 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:57,598 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I apologize for the inconvenience, but it seems there is an issue with retrieving information on Self-RAG and LongLoRA. If you have any other questions or need assistance with something else, please feel free to ask.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KBGrr4lXXF1",
        "outputId": "8d4ca211-9c41-42ff-a700-4bd4e486b88a"
      },
      "source": [
        "import asyncio\n",
        "\n",
        "response = asyncio.run(\n",
        "    agent.run(\n",
        "        user_msg=(\n",
        "            \"Tell me about the evaluation dataset used \"\n",
        "            \"in MetaGPT and compare it against SWE-Bench.\"\n",
        "        )\n",
        "    )\n",
        ")\n",
        "print(str(response))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:01:58,664 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:58,823 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:59,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:01:59,893 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:00,962 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:01,271 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:01,751 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:02,709 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:02,742 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:03,648 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I encountered an issue while trying to retrieve information about the evaluation datasets used in MetaGPT and SWE-Bench. Let me try to provide a comparison based on what I know.\n",
            "\n",
            "MetaGPT uses an evaluation dataset for its testing purposes, but unfortunately, I couldn't retrieve specific details about it. On the other hand, SWE-Bench also utilizes an evaluation dataset for its evaluations. \n",
            "\n",
            "If you have any other questions or need further information, feel free to ask.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzhrevyqXaBl",
        "outputId": "a4a00de8-b201-4541-aaf0-5f1d87490a05"
      },
      "source": [
        "import asyncio\n",
        "\n",
        "response = asyncio.run(\n",
        "    agent.run(\n",
        "        user_msg=(\n",
        "            \"Compare and contrast the LoRA papers (LongLoRA, LoftQ). \"\n",
        "            \"Analyze the approach in each paper first.\"\n",
        "        )\n",
        "    )\n",
        ")\n",
        "print(str(response))\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-14 18:02:05,572 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:06,088 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:06,346 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:06,799 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:07,282 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:08,117 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:08,510 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:09,602 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:09,975 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-12-14 18:02:10,385 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I apologize for the inconvenience, but I am unable to retrieve information about the LongLoRA and LoftQ papers at the moment. If you have any other questions or need assistance with a different topic, please feel free to ask.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3GB4XZHXd4m"
      },
      "source": [
        "**End of Notebook**\n",
        "\n",
        "This complete notebook covers all 4 lessons for building agentic RAG systems with LlamaIndex:\n",
        "\n",
        "\n",
        "*   Router Engine - Route queries to appropriate tools\n",
        "\n",
        "*   Tool Calling - Create and use custom function tools\n",
        "*   Agent Reasoning Loop - Build agents with multi-step reasoning\n",
        "*   Multi-Document Agent - Scale to multiple documents with tool retrieval"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}